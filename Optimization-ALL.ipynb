{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "import ml_utils as mu\n",
    "from sklearn import metrics as metrics\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def do_grid_search(mod_clf, mod_name, params, group, cv=5, scoring='accuracy', variant=None):\n",
    "#     params['kbest__k'] = [1,3,5,7,10,15,20,25,30,37]#np.linspace(1,X.shape[1],10, dtype = int)\n",
    "#     params['pca__n_components'] = np.linspace(1,10,10, dtype = int)\n",
    "    clf = Pipeline([\n",
    "        ('standardization', StandardScaler()),\n",
    "#         ('pca', PCA()),\n",
    "        ('oversampler', RandomOverSampler()),\n",
    "#         ('kbest', SelectKBest(score_func=f_classif)),\n",
    "        ('classifier', mod_clf)\n",
    "    ])\n",
    "#     with mu.Timer('Hyperparameter Grid Search for %s' %mod_name):\n",
    "    best = mu.grid_search_optimization(clf, params, X, y, Xh, yh, Xv, yv, cv=cv, scoring=scoring)\n",
    "    accuracy = {\n",
    "        \"model\" : mod_name, \n",
    "        \"mean_cv_acc\" : best.best_estimator_.score(X,y),\n",
    "        \"holdout_acc\" : best.best_estimator_.score(Xh,yh),\n",
    "        \"validation_acc\" : best.best_estimator_.score(Xv,yv),\n",
    "        \"date_modified\" : datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"best_params\" : str(best.best_params_),\n",
    "        \"variant\" : variant,\n",
    "        \"cv\": cv\n",
    "    }\n",
    "\n",
    "    yh_pred = best.best_estimator_.predict(Xh)\n",
    "    cnf_matrix=metrics.confusion_matrix(yh, yh_pred)\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, normalize=True,classes=group['description'].split(' vs. '), title=\"%s: %s (Holdout)\"%(group['description'], mod_name))\n",
    "    print(\"HOLDOUT ACCURACY: %.3f\" %best.best_estimator_.score(Xh,yh))\n",
    "\n",
    "    yv_pred = best.best_estimator_.predict(Xv)\n",
    "    cnf_matrix=metrics.confusion_matrix(yv, yv_pred)\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, normalize=True,classes=group['description'].split(' vs. '), title=\"%s: %s (Validation)\"%(group['description'], mod_name))\n",
    "    print(\"VALIDATION ACCURACY: %.3f\" %best.best_estimator_.score(Xv,yv))\n",
    "    print()\n",
    "        \n",
    "    return accuracy\n",
    "\n",
    "def getOptimizedModel(model_name, optim_params):\n",
    "    models = {model['name']: model for model in mu.get_baseline_models()}\n",
    "    model = models[model_name]['model']\n",
    "    \n",
    "    clf = Pipeline([\n",
    "        ('standardization', StandardScaler()),\n",
    "        ('oversampler', RandomOverSampler()),\n",
    "        ('kbest', SelectKBest(score_func=f_classif)),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    clf.set_params(**optim_params)\n",
    "    return clf\n",
    "\n",
    "def getData(data_file):\n",
    "    try:\n",
    "        return pd.read_csv(data_file, index_col=0)\n",
    "    except:\n",
    "        pass\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def addData(new_data, data_file, save=True):\n",
    "    df = getData(data_file = data_file)\n",
    "    df = df.append(new_data, ignore_index=True)\n",
    "    if save:\n",
    "        saveData(df, data_file = data_file)\n",
    "    return df\n",
    "    \n",
    "def saveData(df, data_file):\n",
    "    df[['model', 'mean_cv_acc', 'holdout_acc', 'validation_acc', 'cv', 'best_params', 'date_modified', 'variant']].to_csv(data_file)\n",
    "    \n",
    "def showData(df, name):\n",
    "    if name:\n",
    "        display(df.loc[df.model == name].set_index('model')[['mean_cv_acc', 'holdout_acc', 'validation_acc', 'date_modified', 'variant']])\n",
    "    else:\n",
    "        display(df.set_index('model')[['mean_cv_acc', 'holdout_acc', 'validation_acc', 'date_modified', 'variant']])\n",
    "            \n",
    "def delete_row(data_file, index = None, last=False):\n",
    "    if not (index or last):\n",
    "        return\n",
    "    df = getData(data_file = data_file)\n",
    "    if last:\n",
    "        df = df.drop(df.index[len(df)-1])\n",
    "    if index:\n",
    "        df = df.drop(index)\n",
    "    saveData(df, data_file = data_file)\n",
    "    return df\n",
    "\n",
    "def plot_results(title, data_file, plot_file, variant=None):\n",
    "    %matplotlib inline\n",
    "    \n",
    "    if variant:\n",
    "        d = getData(data_file = data_file).loc[df.variant == variant].groupby('model').first()\n",
    "    else:\n",
    "        d = getData(data_file = data_file).loc[df.variant.isnull()].groupby('model').first()\n",
    "\n",
    "    if variant:\n",
    "        title = '%s (%s)' %(title, variant)\n",
    "    \n",
    "    ax = d.drop(['cv'], axis=1).plot(kind='bar', figsize=(10,6), rot=0)\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_ybound((0,1.1))\n",
    "    ax.set_title(title)\n",
    "    l = ax.legend(labels=['cross-val accuracy','holdout accuracy', 'validation accuracy'])\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig('images/%s'%plot_file)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================\n",
      "====\n",
      "====\n",
      "====                         Starting MSA vs. PSP\n",
      "====                                      10FOLDMCC\n",
      "====\n",
      "====\n",
      "===================================================================================\n",
      "# Tuning hyper-parameters for make_scorer(matthews_corrcoef)\n",
      "\n",
      "Fitting 10 folds for each of 600 candidates, totalling 6000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6000 out of 6000 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 341}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.087 (+/-0.600) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 1}\n",
      "0.046 (+/-0.466) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 21}\n",
      "0.113 (+/-0.624) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 41}\n",
      "0.152 (+/-0.594) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 61}\n",
      "0.107 (+/-0.630) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 81}\n",
      "0.151 (+/-0.570) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 101}\n",
      "0.177 (+/-0.627) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 121}\n",
      "0.096 (+/-0.623) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 141}\n",
      "0.085 (+/-0.587) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 161}\n",
      "0.168 (+/-0.748) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 181}\n",
      "0.087 (+/-0.600) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 201}\n",
      "0.098 (+/-0.616) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 221}\n",
      "0.122 (+/-0.534) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 241}\n",
      "0.063 (+/-0.591) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 261}\n",
      "0.177 (+/-0.627) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 281}\n",
      "0.179 (+/-0.568) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 301}\n",
      "0.135 (+/-0.613) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 321}\n",
      "0.123 (+/-0.577) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 341}\n",
      "0.171 (+/-0.655) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 361}\n",
      "0.101 (+/-0.557) for {'classifier__learning_rate': 0.0001, 'classifier__n_estimators': 381}\n",
      "0.083 (+/-0.559) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 1}\n",
      "0.093 (+/-0.485) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 21}\n",
      "0.185 (+/-0.562) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 41}\n",
      "0.107 (+/-0.630) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 61}\n",
      "0.111 (+/-0.541) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 81}\n",
      "0.161 (+/-0.526) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 101}\n",
      "0.246 (+/-0.673) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 121}\n",
      "0.110 (+/-0.641) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 141}\n",
      "0.063 (+/-0.591) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 161}\n",
      "0.181 (+/-0.621) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 181}\n",
      "0.178 (+/-0.525) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 201}\n",
      "0.116 (+/-0.534) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 221}\n",
      "0.099 (+/-0.596) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 241}\n",
      "0.145 (+/-0.564) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 261}\n",
      "0.161 (+/-0.580) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 281}\n",
      "0.191 (+/-0.491) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 301}\n",
      "0.158 (+/-0.589) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 321}\n",
      "0.145 (+/-0.564) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 341}\n",
      "0.158 (+/-0.589) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 361}\n",
      "0.049 (+/-0.557) for {'classifier__learning_rate': 0.00012689610031679221, 'classifier__n_estimators': 381}\n",
      "0.169 (+/-0.690) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 1}\n",
      "0.120 (+/-0.576) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 21}\n",
      "0.109 (+/-0.549) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 41}\n",
      "0.170 (+/-0.610) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 61}\n",
      "0.190 (+/-0.772) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 81}\n",
      "0.145 (+/-0.564) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 101}\n",
      "0.124 (+/-0.599) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 121}\n",
      "0.159 (+/-0.548) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 141}\n",
      "0.158 (+/-0.535) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 161}\n",
      "0.239 (+/-0.716) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 181}\n",
      "0.080 (+/-0.533) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 201}\n",
      "0.029 (+/-0.525) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 221}\n",
      "0.140 (+/-0.556) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 241}\n",
      "0.087 (+/-0.600) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 261}\n",
      "0.156 (+/-0.587) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 281}\n",
      "0.066 (+/-0.544) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 301}\n",
      "0.161 (+/-0.526) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 321}\n",
      "0.217 (+/-0.577) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 341}\n",
      "0.206 (+/-0.501) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 361}\n",
      "0.241 (+/-0.558) for {'classifier__learning_rate': 0.00016102620275609391, 'classifier__n_estimators': 381}\n",
      "0.228 (+/-0.776) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 1}\n",
      "0.126 (+/-0.601) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 21}\n",
      "0.152 (+/-0.594) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 41}\n",
      "0.191 (+/-0.628) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 61}\n",
      "0.170 (+/-0.610) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 81}\n",
      "0.185 (+/-0.562) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 101}\n",
      "0.145 (+/-0.564) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 121}\n",
      "0.211 (+/-0.671) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 141}\n",
      "0.073 (+/-0.569) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 161}\n",
      "0.091 (+/-0.595) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 181}\n",
      "0.163 (+/-0.606) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 201}\n",
      "0.114 (+/-0.636) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 221}\n",
      "0.072 (+/-0.607) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 241}\n",
      "0.110 (+/-0.641) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 261}\n",
      "0.072 (+/-0.607) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 281}\n",
      "0.089 (+/-0.525) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 301}\n",
      "0.055 (+/-0.567) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 321}\n",
      "0.158 (+/-0.589) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 341}\n",
      "0.247 (+/-0.588) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 361}\n",
      "0.181 (+/-0.614) for {'classifier__learning_rate': 0.00020433597178569417, 'classifier__n_estimators': 381}\n",
      "0.055 (+/-0.567) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 1}\n",
      "0.177 (+/-0.627) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 21}\n",
      "0.049 (+/-0.557) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 41}\n",
      "0.158 (+/-0.589) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 61}\n",
      "0.145 (+/-0.564) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 81}\n",
      "0.107 (+/-0.630) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 101}\n",
      "0.055 (+/-0.567) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 121}\n",
      "0.120 (+/-0.576) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 141}\n",
      "0.098 (+/-0.616) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 161}\n",
      "0.190 (+/-0.564) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 181}\n",
      "0.114 (+/-0.586) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 201}\n",
      "0.179 (+/-0.568) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 221}\n",
      "0.060 (+/-0.545) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 241}\n",
      "0.073 (+/-0.569) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 261}\n",
      "0.150 (+/-0.516) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 281}\n",
      "0.207 (+/-0.669) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 301}\n",
      "0.173 (+/-0.673) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 321}\n",
      "0.107 (+/-0.630) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 341}\n",
      "0.072 (+/-0.607) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 361}\n",
      "0.053 (+/-0.541) for {'classifier__learning_rate': 0.00025929437974046669, 'classifier__n_estimators': 381}\n",
      "0.230 (+/-0.720) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 1}\n",
      "0.217 (+/-0.763) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 21}\n",
      "0.089 (+/-0.592) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 41}\n",
      "0.195 (+/-0.683) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 61}\n",
      "0.063 (+/-0.591) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 81}\n",
      "0.159 (+/-0.569) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 101}\n",
      "0.135 (+/-0.494) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 121}\n",
      "0.085 (+/-0.587) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 141}\n",
      "0.141 (+/-0.621) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 161}\n",
      "0.155 (+/-0.545) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 181}\n",
      "0.110 (+/-0.641) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 201}\n",
      "0.152 (+/-0.594) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 221}\n",
      "0.113 (+/-0.530) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 241}\n",
      "0.139 (+/-0.610) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 261}\n",
      "0.122 (+/-0.616) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 281}\n",
      "0.085 (+/-0.587) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 301}\n",
      "0.171 (+/-0.669) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 321}\n",
      "0.188 (+/-0.646) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 341}\n",
      "0.152 (+/-0.594) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 361}\n",
      "0.197 (+/-0.403) for {'classifier__learning_rate': 0.00032903445623126676, 'classifier__n_estimators': 381}\n",
      "0.205 (+/-0.757) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 1}\n",
      "0.124 (+/-0.547) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 21}\n",
      "0.101 (+/-0.557) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 41}\n",
      "0.049 (+/-0.557) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 61}\n",
      "0.098 (+/-0.531) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 81}\n",
      "0.063 (+/-0.591) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 101}\n",
      "0.188 (+/-0.646) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 121}\n",
      "0.177 (+/-0.645) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 141}\n",
      "0.095 (+/-0.583) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 161}\n",
      "0.098 (+/-0.616) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 181}\n",
      "0.085 (+/-0.636) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 201}\n",
      "0.073 (+/-0.569) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 221}\n",
      "0.093 (+/-0.656) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 241}\n",
      "0.172 (+/-0.733) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 261}\n",
      "0.153 (+/-0.633) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 281}\n",
      "0.128 (+/-0.596) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 301}\n",
      "0.201 (+/-0.696) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 321}\n",
      "0.111 (+/-0.601) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 341}\n",
      "0.132 (+/-0.590) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 361}\n",
      "0.166 (+/-0.617) for {'classifier__learning_rate': 0.00041753189365604002, 'classifier__n_estimators': 381}\n",
      "0.126 (+/-0.601) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 1}\n",
      "0.109 (+/-0.549) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 21}\n",
      "0.087 (+/-0.600) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 41}\n",
      "0.167 (+/-0.599) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 61}\n",
      "0.073 (+/-0.569) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 81}\n",
      "0.212 (+/-0.646) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 101}\n",
      "0.178 (+/-0.525) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 121}\n",
      "0.110 (+/-0.641) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 141}\n",
      "0.084 (+/-0.606) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 161}\n",
      "0.106 (+/-0.603) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 181}\n",
      "0.117 (+/-0.660) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 201}\n",
      "0.147 (+/-0.576) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 221}\n",
      "0.141 (+/-0.621) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 241}\n",
      "0.210 (+/-0.585) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 261}\n",
      "0.144 (+/-0.643) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 281}\n",
      "0.166 (+/-0.617) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 301}\n",
      "0.138 (+/-0.579) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 321}\n",
      "0.196 (+/-0.661) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 341}\n",
      "0.196 (+/-0.661) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 361}\n",
      "0.139 (+/-0.610) for {'classifier__learning_rate': 0.00052983169062837071, 'classifier__n_estimators': 381}\n",
      "0.085 (+/-0.636) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 1}\n",
      "0.092 (+/-0.574) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 21}\n",
      "0.177 (+/-0.627) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 41}\n",
      "0.208 (+/-0.591) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 61}\n",
      "0.128 (+/-0.596) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 81}\n",
      "0.091 (+/-0.595) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 101}\n",
      "0.169 (+/-0.598) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 121}\n",
      "0.077 (+/-0.564) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 141}\n",
      "0.161 (+/-0.526) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 161}\n",
      "0.163 (+/-0.606) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 181}\n",
      "0.103 (+/-0.634) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 201}\n",
      "0.196 (+/-0.661) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 221}\n",
      "0.133 (+/-0.550) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 241}\n",
      "0.207 (+/-0.669) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 261}\n",
      "0.207 (+/-0.669) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 281}\n",
      "0.297 (+/-0.510) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 301}\n",
      "0.223 (+/-0.631) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 321}\n",
      "0.223 (+/-0.631) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 341}\n",
      "0.177 (+/-0.627) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 361}\n",
      "0.188 (+/-0.630) for {'classifier__learning_rate': 0.00067233575364993351, 'classifier__n_estimators': 381}\n",
      "0.063 (+/-0.591) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 1}\n",
      "0.141 (+/-0.619) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 21}\n",
      "0.114 (+/-0.586) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 41}\n",
      "0.114 (+/-0.586) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 61}\n",
      "0.193 (+/-0.590) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 81}\n",
      "0.096 (+/-0.614) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 101}\n",
      "0.125 (+/-0.582) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 121}\n",
      "0.093 (+/-0.656) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 141}\n",
      "0.188 (+/-0.646) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 161}\n",
      "0.079 (+/-0.629) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 181}\n",
      "0.220 (+/-0.592) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 201}\n",
      "0.164 (+/-0.644) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 221}\n",
      "0.212 (+/-0.462) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 241}\n",
      "0.199 (+/-0.576) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 261}\n",
      "0.233 (+/-0.542) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 281}\n",
      "0.201 (+/-0.696) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 301}\n",
      "0.221 (+/-0.621) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 321}\n",
      "0.223 (+/-0.653) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 341}\n",
      "0.177 (+/-0.627) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 361}\n",
      "0.242 (+/-0.681) for {'classifier__learning_rate': 0.00085316785241728059, 'classifier__n_estimators': 381}\n",
      "0.123 (+/-0.577) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 1}\n",
      "0.181 (+/-0.621) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 21}\n",
      "0.133 (+/-0.550) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 41}\n",
      "0.164 (+/-0.577) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 61}\n",
      "0.110 (+/-0.641) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 81}\n",
      "0.173 (+/-0.574) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 101}\n",
      "0.250 (+/-0.731) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 121}\n",
      "0.115 (+/-0.649) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 141}\n",
      "0.210 (+/-0.585) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 161}\n",
      "0.166 (+/-0.617) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 181}\n",
      "0.204 (+/-0.599) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 201}\n",
      "0.198 (+/-0.629) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 221}\n",
      "0.197 (+/-0.475) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 241}\n",
      "0.182 (+/-0.643) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 261}\n",
      "0.246 (+/-0.636) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 281}\n",
      "0.177 (+/-0.627) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 301}\n",
      "0.176 (+/-0.598) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 321}\n",
      "0.205 (+/-0.681) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 341}\n",
      "0.224 (+/-0.746) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 361}\n",
      "0.294 (+/-0.751) for {'classifier__learning_rate': 0.0010826367338740541, 'classifier__n_estimators': 381}\n",
      "0.132 (+/-0.591) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 1}\n",
      "0.177 (+/-0.627) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 21}\n",
      "0.049 (+/-0.557) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 41}\n",
      "0.182 (+/-0.643) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 61}\n",
      "0.181 (+/-0.621) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 81}\n",
      "0.093 (+/-0.656) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 101}\n",
      "0.201 (+/-0.696) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 121}\n",
      "0.163 (+/-0.606) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 141}\n",
      "0.133 (+/-0.550) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 161}\n",
      "0.117 (+/-0.660) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 181}\n",
      "0.133 (+/-0.550) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 201}\n",
      "0.300 (+/-0.527) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 221}\n",
      "0.318 (+/-0.475) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 241}\n",
      "0.170 (+/-0.594) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 261}\n",
      "0.370 (+/-0.508) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 281}\n",
      "0.299 (+/-0.607) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 301}\n",
      "0.204 (+/-0.557) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 321}\n",
      "0.283 (+/-0.749) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 341}\n",
      "0.251 (+/-0.697) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 361}\n",
      "0.288 (+/-0.675) for {'classifier__learning_rate': 0.0013738237958832637, 'classifier__n_estimators': 381}\n",
      "0.113 (+/-0.530) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 1}\n",
      "0.192 (+/-0.646) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 21}\n",
      "0.087 (+/-0.600) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 41}\n",
      "0.200 (+/-0.655) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 61}\n",
      "0.135 (+/-0.613) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 81}\n",
      "0.249 (+/-0.553) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 101}\n",
      "0.210 (+/-0.585) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 121}\n",
      "0.183 (+/-0.615) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 141}\n",
      "0.188 (+/-0.630) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 161}\n",
      "0.309 (+/-0.456) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 181}\n",
      "0.229 (+/-0.617) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 201}\n",
      "0.258 (+/-0.651) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 221}\n",
      "0.188 (+/-0.644) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 241}\n",
      "0.249 (+/-0.785) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 261}\n",
      "0.256 (+/-0.633) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 281}\n",
      "0.295 (+/-0.662) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 301}\n",
      "0.385 (+/-0.581) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 321}\n",
      "0.261 (+/-0.653) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 341}\n",
      "0.288 (+/-0.675) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 361}\n",
      "0.270 (+/-0.630) for {'classifier__learning_rate': 0.0017433288221999873, 'classifier__n_estimators': 381}\n",
      "0.126 (+/-0.601) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 1}\n",
      "0.250 (+/-0.687) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 21}\n",
      "0.115 (+/-0.556) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 41}\n",
      "0.184 (+/-0.674) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 61}\n",
      "0.202 (+/-0.588) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 81}\n",
      "0.188 (+/-0.630) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 101}\n",
      "0.270 (+/-0.543) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 121}\n",
      "0.202 (+/-0.649) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 141}\n",
      "0.200 (+/-0.639) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 161}\n",
      "0.316 (+/-0.566) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 181}\n",
      "0.302 (+/-0.419) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 201}\n",
      "0.284 (+/-0.727) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 221}\n",
      "0.264 (+/-0.645) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 241}\n",
      "0.258 (+/-0.651) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 261}\n",
      "0.365 (+/-0.500) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 281}\n",
      "0.431 (+/-0.589) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 301}\n",
      "0.433 (+/-0.657) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 321}\n",
      "0.291 (+/-0.445) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 341}\n",
      "0.351 (+/-0.512) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 361}\n",
      "0.306 (+/-0.718) for {'classifier__learning_rate': 0.0022122162910704502, 'classifier__n_estimators': 381}\n",
      "0.147 (+/-0.576) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 1}\n",
      "0.109 (+/-0.549) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 21}\n",
      "0.171 (+/-0.669) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 41}\n",
      "0.117 (+/-0.660) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 61}\n",
      "0.242 (+/-0.681) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 81}\n",
      "0.226 (+/-0.718) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 101}\n",
      "0.193 (+/-0.623) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 121}\n",
      "0.246 (+/-0.684) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 141}\n",
      "0.256 (+/-0.707) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 161}\n",
      "0.355 (+/-0.501) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 181}\n",
      "0.305 (+/-0.701) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 201}\n",
      "0.280 (+/-0.659) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 221}\n",
      "0.350 (+/-0.420) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 241}\n",
      "0.345 (+/-0.597) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 261}\n",
      "0.301 (+/-0.628) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 281}\n",
      "0.339 (+/-0.687) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 301}\n",
      "0.420 (+/-0.597) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 321}\n",
      "0.404 (+/-0.499) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 341}\n",
      "0.399 (+/-0.566) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 361}\n",
      "0.274 (+/-0.741) for {'classifier__learning_rate': 0.0028072162039411755, 'classifier__n_estimators': 381}\n",
      "0.251 (+/-0.685) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 1}\n",
      "0.087 (+/-0.600) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 21}\n",
      "0.117 (+/-0.660) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 41}\n",
      "0.188 (+/-0.637) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 61}\n",
      "0.265 (+/-0.336) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 81}\n",
      "0.242 (+/-0.668) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 101}\n",
      "0.209 (+/-0.614) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 121}\n",
      "0.213 (+/-0.595) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 141}\n",
      "0.306 (+/-0.718) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 161}\n",
      "0.306 (+/-0.718) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 181}\n",
      "0.288 (+/-0.678) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 201}\n",
      "0.327 (+/-0.696) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 221}\n",
      "0.309 (+/-0.657) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 241}\n",
      "0.394 (+/-0.476) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 261}\n",
      "0.371 (+/-0.498) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 281}\n",
      "0.336 (+/-0.551) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 301}\n",
      "0.390 (+/-0.784) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 321}\n",
      "0.356 (+/-0.623) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 341}\n",
      "0.319 (+/-0.558) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 361}\n",
      "0.367 (+/-0.615) for {'classifier__learning_rate': 0.0035622478902624442, 'classifier__n_estimators': 381}\n",
      "0.087 (+/-0.600) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 1}\n",
      "0.093 (+/-0.656) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 21}\n",
      "0.191 (+/-0.579) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 41}\n",
      "0.189 (+/-0.606) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 61}\n",
      "0.208 (+/-0.653) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 81}\n",
      "0.248 (+/-0.406) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 101}\n",
      "0.225 (+/-0.432) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 121}\n",
      "0.327 (+/-0.411) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 141}\n",
      "0.250 (+/-0.617) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 161}\n",
      "0.309 (+/-0.657) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 181}\n",
      "0.346 (+/-0.535) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 201}\n",
      "0.438 (+/-0.576) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 221}\n",
      "0.338 (+/-0.689) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 241}\n",
      "0.375 (+/-0.507) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 261}\n",
      "0.438 (+/-0.576) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 281}\n",
      "0.438 (+/-0.576) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 301}\n",
      "0.455 (+/-0.638) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 321}\n",
      "0.368 (+/-0.596) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 341}\n",
      "0.413 (+/-0.517) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 361}\n",
      "0.397 (+/-0.636) for {'classifier__learning_rate': 0.0045203536563602409, 'classifier__n_estimators': 381}\n",
      "0.137 (+/-0.624) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 1}\n",
      "0.110 (+/-0.641) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 21}\n",
      "0.175 (+/-0.631) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 41}\n",
      "0.228 (+/-0.667) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 61}\n",
      "0.293 (+/-0.644) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 81}\n",
      "0.234 (+/-0.689) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 101}\n",
      "0.315 (+/-0.679) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 121}\n",
      "0.421 (+/-0.540) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 141}\n",
      "0.397 (+/-0.553) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 161}\n",
      "0.393 (+/-0.488) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 181}\n",
      "0.330 (+/-0.530) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 201}\n",
      "0.353 (+/-0.664) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 221}\n",
      "0.389 (+/-0.632) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 241}\n",
      "0.304 (+/-0.702) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 261}\n",
      "0.390 (+/-0.784) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 281}\n",
      "0.345 (+/-0.729) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 301}\n",
      "0.398 (+/-0.665) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 321}\n",
      "0.418 (+/-0.697) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 341}\n",
      "0.366 (+/-0.643) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 361}\n",
      "0.383 (+/-0.701) for {'classifier__learning_rate': 0.0057361525104486812, 'classifier__n_estimators': 381}\n",
      "0.087 (+/-0.600) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 1}\n",
      "0.107 (+/-0.565) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 21}\n",
      "0.207 (+/-0.669) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 41}\n",
      "0.258 (+/-0.651) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 61}\n",
      "0.288 (+/-0.678) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 81}\n",
      "0.327 (+/-0.605) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 101}\n",
      "0.376 (+/-0.609) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 121}\n",
      "0.395 (+/-0.485) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 141}\n",
      "0.353 (+/-0.699) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 161}\n",
      "0.312 (+/-0.730) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 181}\n",
      "0.394 (+/-0.807) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 201}\n",
      "0.407 (+/-0.711) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 221}\n",
      "0.361 (+/-0.587) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 241}\n",
      "0.414 (+/-0.472) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 261}\n",
      "0.430 (+/-0.626) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 281}\n",
      "0.475 (+/-0.506) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 301}\n",
      "0.365 (+/-0.666) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 321}\n",
      "0.454 (+/-0.550) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 341}\n",
      "0.485 (+/-0.645) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 361}\n",
      "0.509 (+/-0.609) for {'classifier__learning_rate': 0.0072789538439831459, 'classifier__n_estimators': 381}\n",
      "0.137 (+/-0.624) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 1}\n",
      "0.202 (+/-0.588) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 21}\n",
      "0.211 (+/-0.668) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 41}\n",
      "0.306 (+/-0.718) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 61}\n",
      "0.373 (+/-0.518) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 81}\n",
      "0.344 (+/-0.543) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 101}\n",
      "0.489 (+/-0.590) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 121}\n",
      "0.372 (+/-0.477) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 141}\n",
      "0.456 (+/-0.605) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 161}\n",
      "0.430 (+/-0.713) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 181}\n",
      "0.391 (+/-0.596) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 201}\n",
      "0.369 (+/-0.540) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 221}\n",
      "0.397 (+/-0.576) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 241}\n",
      "0.443 (+/-0.712) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 261}\n",
      "0.469 (+/-0.565) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 281}\n",
      "0.490 (+/-0.624) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 301}\n",
      "0.459 (+/-0.618) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 321}\n",
      "0.509 (+/-0.609) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 341}\n",
      "0.464 (+/-0.648) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 361}\n",
      "0.532 (+/-0.631) for {'classifier__learning_rate': 0.0092367085718738657, 'classifier__n_estimators': 381}\n",
      "0.068 (+/-0.499) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 1}\n",
      "0.253 (+/-0.543) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 21}\n",
      "0.269 (+/-0.426) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 41}\n",
      "0.281 (+/-0.651) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 61}\n",
      "0.417 (+/-0.600) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 81}\n",
      "0.389 (+/-0.679) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 101}\n",
      "0.370 (+/-0.540) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 121}\n",
      "0.411 (+/-0.516) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 141}\n",
      "0.441 (+/-0.554) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 161}\n",
      "0.366 (+/-0.656) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 181}\n",
      "0.482 (+/-0.625) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 201}\n",
      "0.471 (+/-0.561) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 221}\n",
      "0.444 (+/-0.487) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 241}\n",
      "0.485 (+/-0.645) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 261}\n",
      "0.466 (+/-0.556) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 281}\n",
      "0.489 (+/-0.587) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 301}\n",
      "0.466 (+/-0.678) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 321}\n",
      "0.508 (+/-0.609) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 341}\n",
      "0.492 (+/-0.620) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 361}\n",
      "0.465 (+/-0.725) for {'classifier__learning_rate': 0.011721022975334805, 'classifier__n_estimators': 381}\n",
      "0.098 (+/-0.616) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 1}\n",
      "0.162 (+/-0.632) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 21}\n",
      "0.392 (+/-0.522) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 41}\n",
      "0.348 (+/-0.593) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 61}\n",
      "0.421 (+/-0.579) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 81}\n",
      "0.396 (+/-0.672) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 101}\n",
      "0.410 (+/-0.662) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 121}\n",
      "0.443 (+/-0.531) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 141}\n",
      "0.443 (+/-0.531) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 161}\n",
      "0.469 (+/-0.565) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 181}\n",
      "0.471 (+/-0.600) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 201}\n",
      "0.466 (+/-0.448) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 221}\n",
      "0.506 (+/-0.637) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 241}\n",
      "0.532 (+/-0.567) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 261}\n",
      "0.485 (+/-0.700) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 281}\n",
      "0.482 (+/-0.671) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 301}\n",
      "0.529 (+/-0.532) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 321}\n",
      "0.509 (+/-0.690) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 341}\n",
      "0.529 (+/-0.658) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 361}\n",
      "0.550 (+/-0.585) for {'classifier__learning_rate': 0.014873521072935119, 'classifier__n_estimators': 381}\n",
      "0.055 (+/-0.567) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 1}\n",
      "0.231 (+/-0.742) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 21}\n",
      "0.324 (+/-0.549) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 41}\n",
      "0.343 (+/-0.644) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 61}\n",
      "0.469 (+/-0.565) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 81}\n",
      "0.480 (+/-0.658) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 101}\n",
      "0.445 (+/-0.527) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 121}\n",
      "0.440 (+/-0.590) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 141}\n",
      "0.445 (+/-0.622) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 161}\n",
      "0.485 (+/-0.645) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 181}\n",
      "0.511 (+/-0.604) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 201}\n",
      "0.539 (+/-0.588) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 221}\n",
      "0.529 (+/-0.658) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 241}\n",
      "0.486 (+/-0.667) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 261}\n",
      "0.529 (+/-0.658) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 281}\n",
      "0.529 (+/-0.658) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 301}\n",
      "0.511 (+/-0.640) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 321}\n",
      "0.559 (+/-0.635) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 341}\n",
      "0.553 (+/-0.617) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 361}\n",
      "0.580 (+/-0.676) for {'classifier__learning_rate': 0.018873918221350976, 'classifier__n_estimators': 381}\n",
      "0.230 (+/-0.530) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 1}\n",
      "0.264 (+/-0.708) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 21}\n",
      "0.301 (+/-0.638) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 41}\n",
      "0.361 (+/-0.763) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 61}\n",
      "0.439 (+/-0.573) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 81}\n",
      "0.469 (+/-0.565) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 101}\n",
      "0.419 (+/-0.587) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 121}\n",
      "0.441 (+/-0.569) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 141}\n",
      "0.486 (+/-0.667) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 161}\n",
      "0.422 (+/-0.710) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 181}\n",
      "0.492 (+/-0.620) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 201}\n",
      "0.572 (+/-0.630) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 221}\n",
      "0.602 (+/-0.597) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 241}\n",
      "0.541 (+/-0.620) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 261}\n",
      "0.580 (+/-0.676) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 281}\n",
      "0.511 (+/-0.640) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 301}\n",
      "0.580 (+/-0.553) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 321}\n",
      "0.580 (+/-0.553) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 341}\n",
      "0.559 (+/-0.502) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 361}\n",
      "0.628 (+/-0.523) for {'classifier__learning_rate': 0.023950266199874861, 'classifier__n_estimators': 381}\n",
      "0.085 (+/-0.636) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 1}\n",
      "0.369 (+/-0.648) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 21}\n",
      "0.435 (+/-0.398) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 41}\n",
      "0.411 (+/-0.631) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 61}\n",
      "0.419 (+/-0.587) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 81}\n",
      "0.488 (+/-0.675) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 101}\n",
      "0.492 (+/-0.620) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 121}\n",
      "0.506 (+/-0.637) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 141}\n",
      "0.532 (+/-0.567) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 161}\n",
      "0.529 (+/-0.658) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 181}\n",
      "0.557 (+/-0.774) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 201}\n",
      "0.511 (+/-0.640) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 221}\n",
      "0.607 (+/-0.478) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 241}\n",
      "0.624 (+/-0.531) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 261}\n",
      "0.625 (+/-0.487) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 281}\n",
      "0.649 (+/-0.492) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 301}\n",
      "0.672 (+/-0.424) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 321}\n",
      "0.659 (+/-0.502) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 341}\n",
      "0.672 (+/-0.504) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 361}\n",
      "0.694 (+/-0.391) for {'classifier__learning_rate': 0.030391953823131979, 'classifier__n_estimators': 381}\n",
      "0.058 (+/-0.491) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 1}\n",
      "0.423 (+/-0.528) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 21}\n",
      "0.358 (+/-0.727) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 41}\n",
      "0.392 (+/-0.534) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 61}\n",
      "0.511 (+/-0.640) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 81}\n",
      "0.513 (+/-0.612) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 101}\n",
      "0.529 (+/-0.658) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 121}\n",
      "0.485 (+/-0.480) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 141}\n",
      "0.508 (+/-0.609) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 161}\n",
      "0.539 (+/-0.762) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 181}\n",
      "0.583 (+/-0.587) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 201}\n",
      "0.587 (+/-0.533) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 221}\n",
      "0.629 (+/-0.615) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 241}\n",
      "0.628 (+/-0.523) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 261}\n",
      "0.629 (+/-0.417) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 281}\n",
      "0.679 (+/-0.430) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 301}\n",
      "0.740 (+/-0.407) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 321}\n",
      "0.719 (+/-0.462) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 341}\n",
      "0.740 (+/-0.490) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 361}\n",
      "0.679 (+/-0.430) for {'classifier__learning_rate': 0.038566204211634723, 'classifier__n_estimators': 381}\n",
      "0.098 (+/-0.616) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 1}\n",
      "0.448 (+/-0.482) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 21}\n",
      "0.446 (+/-0.646) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 41}\n",
      "0.443 (+/-0.665) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 61}\n",
      "0.506 (+/-0.637) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 81}\n",
      "0.471 (+/-0.561) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 101}\n",
      "0.511 (+/-0.640) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 121}\n",
      "0.552 (+/-0.635) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 141}\n",
      "0.602 (+/-0.597) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 161}\n",
      "0.586 (+/-0.423) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 181}\n",
      "0.628 (+/-0.523) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 201}\n",
      "0.664 (+/-0.537) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 221}\n",
      "0.687 (+/-0.473) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 241}\n",
      "0.708 (+/-0.506) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 261}\n",
      "0.698 (+/-0.428) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 281}\n",
      "0.677 (+/-0.386) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 301}\n",
      "0.737 (+/-0.460) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 321}\n",
      "0.758 (+/-0.485) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 341}\n",
      "0.701 (+/-0.467) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 361}\n",
      "0.737 (+/-0.460) for {'classifier__learning_rate': 0.048939009184774937, 'classifier__n_estimators': 381}\n",
      "0.063 (+/-0.591) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 1}\n",
      "0.348 (+/-0.552) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 21}\n",
      "0.434 (+/-0.499) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 41}\n",
      "0.485 (+/-0.617) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 61}\n",
      "0.511 (+/-0.640) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 81}\n",
      "0.508 (+/-0.609) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 101}\n",
      "0.538 (+/-0.588) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 121}\n",
      "0.600 (+/-0.468) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 141}\n",
      "0.620 (+/-0.605) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 161}\n",
      "0.622 (+/-0.423) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 181}\n",
      "0.676 (+/-0.393) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 201}\n",
      "0.694 (+/-0.391) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 221}\n",
      "0.669 (+/-0.403) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 241}\n",
      "0.694 (+/-0.391) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 261}\n",
      "0.656 (+/-0.334) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 281}\n",
      "0.694 (+/-0.391) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 301}\n",
      "0.694 (+/-0.391) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 321}\n",
      "0.708 (+/-0.506) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 341}\n",
      "0.694 (+/-0.391) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 361}\n",
      "0.618 (+/-0.383) for {'classifier__learning_rate': 0.062101694189156162, 'classifier__n_estimators': 381}\n",
      "0.087 (+/-0.600) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 1}\n",
      "0.441 (+/-0.806) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 21}\n",
      "0.454 (+/-0.747) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 41}\n",
      "0.438 (+/-0.522) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 61}\n",
      "0.529 (+/-0.658) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 81}\n",
      "0.529 (+/-0.658) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 101}\n",
      "0.573 (+/-0.555) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 121}\n",
      "0.665 (+/-0.433) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 141}\n",
      "0.665 (+/-0.433) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 161}\n",
      "0.677 (+/-0.386) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 181}\n",
      "0.669 (+/-0.403) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 201}\n",
      "0.677 (+/-0.386) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 221}\n",
      "0.609 (+/-0.415) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 241}\n",
      "0.716 (+/-0.429) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 261}\n",
      "0.669 (+/-0.403) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 281}\n",
      "0.630 (+/-0.335) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 301}\n",
      "0.729 (+/-0.535) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 321}\n",
      "0.729 (+/-0.535) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 341}\n",
      "0.644 (+/-0.385) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 361}\n",
      "0.618 (+/-0.383) for {'classifier__learning_rate': 0.078804628156699127, 'classifier__n_estimators': 381}\n",
      "0.253 (+/-0.554) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 1}\n",
      "0.437 (+/-0.549) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 21}\n",
      "0.389 (+/-0.463) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 41}\n",
      "0.527 (+/-0.710) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 61}\n",
      "0.570 (+/-0.536) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 81}\n",
      "0.596 (+/-0.447) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 101}\n",
      "0.622 (+/-0.423) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 121}\n",
      "0.694 (+/-0.391) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 141}\n",
      "0.640 (+/-0.437) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 161}\n",
      "0.609 (+/-0.640) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 181}\n",
      "0.690 (+/-0.447) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 201}\n",
      "0.677 (+/-0.386) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 221}\n",
      "0.758 (+/-0.487) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 241}\n",
      "0.648 (+/-0.480) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 261}\n",
      "0.674 (+/-0.472) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 281}\n",
      "0.694 (+/-0.391) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 301}\n",
      "0.687 (+/-0.475) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 321}\n",
      "0.708 (+/-0.506) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 341}\n",
      "0.661 (+/-0.481) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 361}\n",
      "0.687 (+/-0.473) for {'classifier__learning_rate': 0.10000000000000001, 'classifier__n_estimators': 381}\n",
      "\n",
      "Detailed classification report (holdout):\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.90      0.82      0.86        11\n",
      "          3       0.83      0.91      0.87        11\n",
      "\n",
      "avg / total       0.87      0.86      0.86        22\n",
      "\n",
      "\n",
      "Detailed classification report (validation):\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.57      0.50      0.53         8\n",
      "          3       0.75      0.80      0.77        15\n",
      "\n",
      "avg / total       0.69      0.70      0.69        23\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAAEmCAYAAAAJAaljAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYJqZZfT/AWtt81HJKmyiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a9cade15c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOLDOUT ACCURACY: 0.864\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAAEmCAYAAAAJAaljAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmcFdWZxvHf0+wIKoioLAoKUQnu\nomNW3DFuWdSIJtGYaGJEJ5pk1GiMceJEY5ZxErKQxLiNosYxYoLikmiMcQEBUTAqokiDCyi4Ytje\n+eNUy+XS3bdabvct6Ofrpz7eqjp16lRf+u1zTlWdo4jAzMwqq6t1AczM1hcOmGZmOTlgmpnl5IBp\nZpaTA6aZWU4OmGZmOTlgWuFIulDStetw/Fck/XeVynKipL+XrL8lads8ad/HuW6XdML7Pb4knzMk\nXbKu+djaHDBzkPS8pGWS+pRtny4pJA3K1gdIulnSIkmvS3pc0ollx2yU/dJNbLMLWPP8z0tampXh\nZUm/l9Qj2/dBSXdKWixpiaRHJX0i2zdS0qrsuDclPSXpi7W4huZI6gycD1wmqWt2Hfs1ku6nkv7Q\n0vwjokdEzKlCOdf6oxARh0TEVeuaNzAO+JykvlXIy0o4YOb3HDC6YUXSTkC3sjTXAPOAbYDNgC8A\nL5elOQr4F3CQpK1arbTNOzwiegC7AyNIAQbgNuAuYAugL3AG8EbJcQuy4zYGzgZ+I2lYm5U6nyOB\nf0bE/Ih4F7iB9D28R1IH0ndZjeBUONl1307Zddu6c8DM7xrW/Ad4AnB1WZoRwJUR8XZErIiIaRFx\ne1maE4BfATOA45s6maRfSfpR2bZbJZ2VfT5b0vyS2t7+Lb2giJhP+sUantWeBwO/iYhl2fJARKzV\nxIzkj8BioGLAlNRL0p8kLcxqr3+SNKBk/2BJ92XXchdQXpO/SdJLWa39b5I+2MzpDgHuK1m/CviM\npO4l2w4m/du/Pcv/HEnPZuefJelTzVxLSBqSfd5M0gRJb0h6BNiuLO3lkuZl+x+V9NFs+yjg28Bn\nsxr7Y9n2eyV9OftcJ+l8SXMlvSLpakmbZPsGZeU4QdILWYvmvLKi3gsc2szPyd4HB8z8HgI2lrRj\nVkP5LFDez/YQMFbSsZK2Ls8g2zYS+N9saa4GcB3pF0rZsb2Ag4DxkrYHxgAjIqInKQA839ILkjQQ\n+AQwDXgVmA1cK+mTkrZo5ri6LKhsCjyebZsh6bgmDqkDfk+qeW8NLAV+Xnatj5IC5X+S/qiUuh0Y\nSqr1TiX97JqyE/BUw0pE/AN4Efh0SZrPA9dFxIps/Vngo8AmwPdIP4M8tf+xwLvAVsBJ2VJqMrAr\n0Du7xpskdY2IO4D/Am7Imvi7NJL3idmyL7At0IM1f2YAHwG2B/YHLpC0Y8m+J4HG8rV1ERFeKiyk\nYHQAqen6A2AUqenaEQhgUJauF3AJMBNYCUwnBbWGfM4Hpmef+2VpdmvinAJeAD6WrZ8M/CX7PAR4\nJStTp/dxLW8BS4C5wC+Abtm+AaRfymeBVcDfgKHZvpHZtiXAa9m1Hfs+f567Aouzz1sDK4CNSvZf\nB1zbxLGbZj/zTZrY/wwwqmzb+cCd2eeNgXea+rlnaaYDR2afTwT+XrIvsp9/B2A5sEPJvv8qTdtI\nvouBXbLPF5ZfI6lW+OXs8z3A10r2bZ+dryMwKCvHgJL9j5R+H6Q/MCtr/buzoS2uYbbMNcBxpF+i\n8uY4EbE4Is6JiA+S+gGnA39sqCWSapT/m6VdQGo6NnpXNNK/+vGs7jc9ruTY2cDXSb90r0gaL6lf\nC67jkxGxaURsExFfi4ilWb71ETEmIrYj1QbfLrvOBdlxvSNi14gYn+dkkrpL+nXWvHyDFIg3zWrq\n/UjB8+2SQ+aWHNtB0iVZk/kNVtek12i2l1gM9CzbdjWwr6T+pD7k2RExreQcX1C6gbdE0hJgeDP5\nN9icFLzmNVbuLN9vSHoy60pYQqrBVsq3Qb+y/OZm5yut+b9U8vkdUi20QU/g9ZznspwcMFsgIuaS\nbv58Avi/CmkXAT8i/cPvLelDpL/652b9cS8BewOjJXVsIpvrgaMkbZOlvbkk/+si4iOkwBbApet0\ncWuXfx6pyTm8Ctl9g1RD2jsiNgY+lm0XqbncS9JGJelLuzOOI93IOYAUcAaVHNuYGcAHSjdExAvA\n/aQ+489T8kcg+9n+htTFsVlEbAo80Uz+DRaSasYDGyt31l95NnAM0CvL9/WSfCsNE7aA9N2W5r2C\ntW8iNmVH4LGcaS0nB8yW+xKwX1mNCABJl0oaLqmjpJ7AqaTazKukmuRdpJsku2bLcKA76UbFWrJa\n0ELgt8CkiFiSnWd7SftJ6kLqQ1tKat6/b9mNme9JGpL1UfYh9ck9tC75ZnpmZVwiqTfw3YYd2R+h\nKcD3JHWW9BHg8LJj/0XqY+1OavY2ZyLw8Ua2X0UKih9mzT7QjUjBayGA0qNSFf9IRMRK0h/NC7Ma\n9DDWbC30JAW4hUBHSReQugMavAwMktTU7+D1wJnZDbEerO7zXNFE+nIfJ7upZdXjgNlCEfFsRExp\nYnd34BZSP98cUg3hCEldSTWNn0XESyXLc6RmfnMPK19Pql1dV7KtC6mvdBGpWdaXdNcVScdLmvk+\nLm0ZqfZ2N+lRoidIgerEPAdLmimpqbv+/016BGsRKQDfUbb/OFIN+jVSMC3tBria1BydD8yicgC/\nDdihkS6KP5D6mO+JiBcbNkbELODHwIOkILYT8ECFczQYQ2oGvwRcSbqx1WASKWA9nZX/XdZsvt+U\n/f9VSVMbyfsK0r+Nv5FaNe8Cp+cpVPbv7RNsoI9N1ZJSV5nZhkPSKcCwiPh6rctSC5JOBwZGxH/U\nuiwbGgdMM7Oc3CQ3sw2SpFFKL3XMlnROI/u3lvRXSdOy54g/UTFP1zDNbEOTPbL2NHAgUE96iWB0\n1mfdkGYcMC0ifpndtJsYEYOay9c1TDPbEO1FekJlTkQsIz3TfGRZmmD1kwubkB7lalZTz/+td7pt\n3Ct69u1f62KYtRsLn525KCI2r1Z+HTbeJmLF0lxpY+nCmaQnBxqMi4hxJev9WfOphHrSkxilLgTu\nzG6SbUR6GqVZG0zA7Nm3P8dcdlPlhGZWFWM/PWxu5VT5xYqldNn+mFxp350+9t2I2LOZJI29eFDe\n/ziaNFjOjyXtA1wjaXhErGoq0w0mYJrZ+k7Q5HP8LVbPmm9hDWDtJveXSONCEBEPZs+v9iGN09Ao\n92GaWTEIqOuQb6lsMjA0e1OqM3AsMKEszQukkZ7IRnrqSvbGV1NcwzSz4lClV/jziYgVksaQ3rjq\nAFwRETMlXQRMiYgJpDEOfiPpTFJz/cSo8NiQA6aZFURVm+RExETS2AKl2y4o+TyLNLZAbg6YZlYc\nVaphthYHTDMrBlHVGmZrcMA0s4KQa5hmZrm5hmlmlofyPjJUMw6YZlYMwk1yM7Pc3CQ3M8ujus9h\ntgYHTDMrjjo3yc3MKvNzmGZmefkuuZlZfr5LbmaWk5vkZmY5yK9Gmpnl5xqmmVlOrmGameXhu+Rm\nZvn4OUwzs7z8aqSZWX7uwzQzy8k1TDOznFzDNDPLQe7DNDPLTXUOmGZmFaUZKtwkNzOrTNlSYA6Y\nZlYQcg3TzCyvogfMYvewmlm7IinXkjOvUZKekjRb0jmN7P+ppOnZ8rSkJZXydA3TzIpBoCpNgiap\nAzAWOBCoByZLmhARsxrSRMSZJelPB3arlK9rmGZWCCJf7TJnDXMvYHZEzImIZcB44Mhm0o8Grq+U\nqWuYZlYYLejD7CNpSsn6uIgYV7LeH5hXsl4P7N3EObcBBgN/qXRSB0wzK4wWBMxFEbFnc1k1si2a\nSHss8IeIWFnppA6YZlYYVbxLXg8MLFkfACxoIu2xwGl5MnUfppkVg1qwVDYZGCppsKTOpKA4Ya1T\nStsDvYAH82TqGqaZFYIQdVV6lzwiVkgaA0wCOgBXRMRMSRcBUyKiIXiOBsZHRFPN9TU4YJpZYVTz\nwfWImAhMLNt2Qdn6hS3J0wHTzIqj2C/6OGCaWUGo+K9GOmCaWWE4YJqZ5eSAaWaWgzy8m1WyY9+N\nOGrnLaiT+MfcJdz19Ktr7N9760345PC+vL50BQD3zVnMg3OXvLfv4O37ADDpqUU8/MLrbVv4dszf\nWyuo4uAbrcUBs4YEHLPLlvz8gRdYsnQ539p3MI+/+CYvvblsjXRT69/gphkvr7Gte6c6DtmhDz/8\n63MEcPa+g5nx4pssXb6q7S6gnfL31nqKXsP0mz41NKh3Nxa9vYxX31nOyki/YDtv1TPXsTtu0YN/\nvvI27yxfxdLlq/jnK28zbIserVxiA39vrama42G2Btcwa2iTrh1ZnDXZABYvXc6gXt3WSrdr/40Z\n0qc7r7y1jJsff5klS1ewadeOLF66/L00Ddus9fl7a0XFrmC2Xg1TUki6pmS9o6SFkv6UrW8h6U+S\nHpM0S9LEsuPPlPSupE1aq4y1luffxhMvvcV3J83mB395jqdeeZvP79GvyYNzvdtl68zfW+speg2z\nNZvkbwPDJTX86T0QmF+y/yLgrojYJSKGAeVDyI8mvUD/qVYsY00teXcFvbqtrl306taJ199dsUaa\nt5etZMWq9Cv1wPNL2HrTrunYpSvo1a3Te+k27dZxrWOtdfh7ax15g+WGGjABbgcOzT6Xj2i8FWkI\nJgAiYkbDZ0nbAT2A87PjNkhzFy9l8x6d2ax7JzoIdh+wMTNefHONNBt3Wf2LudNWPd+7sfDky2+x\nQ9+N6Napjm6d6tih70Y8+fJbbVr+9srfW+upq6vLtdRKa3eejAcuyJrhOwNXAB/N9o0FbshGFLkb\n+H1ENIxX1xBc7we2l9Q3Il5p5bK2uVUBNz72Eqd9eCBCPDR3CS+9uYxDd+zDC4vf5fGX3mLkdr3Y\naauerIzgnWUrufbR9CN6Z/kq7nhqEf8xcjAAd/xzEe/4Tmub8PfWigreh6mcoxq1PGPprYjokQ0j\nPxYYCtwJfDMiDsvS9AZGAYcABwHDI2KhpCeAT0XEM5J+AjwbEWMbOccpwCkAPTbfao8Tfn1Pq1yL\nma1t7KeHPVph1PMW6bLF0Oh//OW50j7300Oreu682uL23ATgR8BIYLPSHRHxGnAdcF1WC/2YpGdI\nwfWurK+iMzCHFHQpO34cMA6g75Dh7js3W5+tB4NvtEVnwBXARRHxeOlGSftJ6p597glsB7xAao5f\nGBGDsqUf0D+bqMjMNlACpHxLrbR6wIyI+ohorJ69BzBF0gzS8PC/jYjJpKHkbylLe0u23cw2WMW/\nS95qTfKIWOv1hYi4F7g3+3wZcFkjaQY3su2s6pfQzIqmzu+Sm5nlUOPmdh4OmGZWCMI1TDOz3FzD\nNDPLqeiPFTlgmlkxuA/TzCwfoZq+J56HA6aZFYZrmGZmObkP08wsD/dhmpnlk94lL3bELHYPq5m1\nK9UcfEPSKElPSZotqXxGh4Y0x2RT5MyUdF2lPF3DNLPCqFYNU1IH0pCQB5JmdpgsaUJEzCpJMxQ4\nF/hwRCyW1LdSvg6YZlYMquqrkXsBsyNiDoCk8cCRwKySNCcDYyNiMUCeWR3cJDezQmjheJh9JE0p\nWU4py64/MK9kvT7bVuoDwAckPSDpIUmjKpXRNUwzK4gWjXW5qMIUFY1lVD4rQ0fS7A4jgQHA/ZKG\nR8SSpjJ1DdPMCqOKN33qgYEl6wOABY2kuTUilkfEc8BTpADaJAdMMyuMKo64PhkYKmmwpM6kGRsm\nlKX5I7Bvdt4+pCb6nOYydcA0s2LIWbvMEy8jYgUwBpgEPAncGBEzJV0k6Ygs2STgVUmzgL8C34qI\nV5vL132YZlYIaQDh6tXhImIiMLFs2wUlnwM4K1tyccA0s8Io+Is+DphmVhxFfzXSAdPMisGDb5iZ\n5aOWPYdZEw6YZlYYBY+XDphmVhwdPM2umVll6RlLB0wzs1wKXsFsOmBK2ri5AyPijeoXx8zas/W5\nhjmTNLpH6RU0rAewdSuWy8zaoYLHy6YDZkQMbGqfmVm1ifRoUZHlenFT0rGSvp19HiBpj9Ytlpm1\nR3XKt9SsfJUSSPo5aQikz2eb3gF+1ZqFMrN2SKKuLt9SK3nukn8oInaXNA0gIl7LxpczM6saAXUF\n78TMEzCXS6ojG95d0mbAqlYtlZm1SwWPl7n6MMcCNwObS/oe8Hfg0lYtlZm1S1Uccb1VVKxhRsTV\nkh4FDsg2HR0RT7RuscysvWnBfD01k/dNnw7AclKz3NNamFmrKHofZp675OcB1wP9SDOvXSfp3NYu\nmJm1P3VSrqVW8tQwPwfsERHvAEi6GHgU+EFrFszM2pd0l7zWpWhenoA5tyxdRypMRWlm1mI1vqGT\nR3ODb/yU1Gf5DjBT0qRs/SDSnXIzs6oqeLxstobZcCd8JvDnku0PtV5xzKw9W29rmBHxu7YsiJm1\nbxtEH6ak7YCLgWFA14btEfGBViyXmbVD6/1jRcCVwO9JfwAOAW4ExrdimcysHZKK/1hRnoDZPSIm\nAUTEsxFxPmn0IjOzqmp426fSUit5Hiv6l1JP7LOSvgrMB/q2brHMrD0q+k2fPDXMM4EewBnAh4GT\ngZNas1Bm1j5Vs4YpaZSkpyTNlnROI/tPlLRQ0vRs+XKlPPMMvvFw9vFNVg8ibGZWVaJ6/ZOSOpBG\nWjsQqAcmS5oQEbPKkt4QEWPy5tvcg+u3kI2B2ZiI+HTek7SFgZt05UeH71jrYlgL9RqR+9+qbeiq\n2z+5FzA7IuYASBoPHAmUB8wWaa6G+fN1ydjMrKU65I+YfSRNKVkfFxHjStb7A/NK1uuBvRvJ5zOS\nPgY8DZwZEfMaSfOe5h5cv6dymc3MqkO06KbPoojYs0J25cpbzLcB10fEv7Ib2lcB+zV3Uo9taWaF\nUcVZI+uB0qnCBwALShNExKsR8a9s9TdAxdlwHTDNrDCqGDAnA0MlDc4mbTwWmFCaQNJWJatHAE9W\nyjTviOtI6lISjc3Mqio9MlSduz4RsULSGGASacaIKyJipqSLgCkRMQE4Q9IRwArgNeDESvnmeZd8\nL+B3wCbA1pJ2Ab4cEae/76sxM2tENQffiIiJwMSybReUfD4XaNHsEXma5P8DHAa8mp3kMfxqpJlV\nmYAOdcq11EqeJnldRMwtqyqvbKXymFk7VvSbKnkC5rysWR7Z0/Onk55ZMjOrqoK/Sp4rYJ5KapZv\nDbwM3J1tMzOrGtV46LY88rxL/grplryZWasqeLzMdZf8NzTyTnlEnNIqJTKzdmu9n6KC1ARv0BX4\nFGu+o2lmts4a7pIXWZ4m+Q2l65KuAe5qtRKZWfuU/y2emsn9pk+JwcA21S6ImZkaHTOjOPL0YS5m\ndR9mHekVorVGLzYzWxfr/TS72Vw+u5Dm8QFYFRFNDipsZrYuih4wm32wPguOt0TEymxxsDSzViMp\n11Ired5EekTS7q1eEjNr1yToUJdvqZXm5vTpGBErgI8AJ0t6Fnib1NUQEeEgamZVtT6/6fMIsDvw\nyTYqi5m1Y+v7TR8BRMSzbVQWM2vnCl7BbDZgbi7prKZ2RsRPWqE8ZtZuibr1+DnMDkAPGp99zcys\nqtKskbUuRfOaC5gvRsRFbVYSM2vf1vNXIwtedDPbkKzvg2/s32alMDNjPX6sKCJea8uCmJkVPF6+\nr9GKzMyqTmwYk6CZmbU+UdP3xPNwwDSzwih2uHTANLOCENDBNUwzs3wKHi8L38dqZu1GvrEw8/Zz\nShol6SlJsyU1OUuEpKMkhaQ9K+XpgGlmhdBwlzzPUjEvqQMwFjgEGAaMljSskXQ9gTOAh/OU0QHT\nzAqjijXMvYDZETEnIpYB44EjG0n3n8APgXfzZOqAaWaFoZxLDv2BeSXr9dm21eeSdgMGRsSf8pbP\nN33MrBCkFt0l7yNpSsn6uIgYV5pdI8e8NyeZpDrgp8CJLSmjA6aZFUYLHlxfFBHN3aSpBwaWrA8A\nFpSs9wSGA/dm59wSmCDpiIgoDcRrcMA0s8Ko4lNFk4GhkgaTpgk/FjiuYWdEvA70ee+80r3AN5sL\nluA+TDMrECnfUkk2geMYYBLwJHBjRMyUdJGkI95v+VzDNLNCSI8VVa+OGRETgYll2y5oIu3IPHk6\nYJpZYRT9TR8HTDMrCKGCD7/hgGlmheDBN8zM8sp5Q6eWHDDNrDAcMM3Mcip6H6afw6yxOyfdwc4f\n3J4P7jCEy354yVr7L//pT9ht52GM2G1nDjlof+bOnfvevmuvvorhOw5l+I5Dufbqq9qy2O3egR/a\nkcdu+Q5P3PpdvvnFA9faP3DLXtwx7gwevP5sHrnhXA7+yOqBcr550kE8cet3eeyW73DAPju2ZbEL\nTaR5yfMsteKAWUMrV67k62ecxq233c60GbO4afz1PDlr1hppdt1tNx54aAqTp83gU58+ivPO/Q8A\nXnvtNS7+/vf42wMPc/8/HuHi73+PxYsX1+Iy2p26OvHf5xzDkWN+wW6f+T5Hj9qDHbbdco00Z395\nFDffNZV9Rl/KF879PZef+1kAdth2S44+eHd2P+pijjjtF1x+7jHUFXwu7raknP/VigNmDU1+5BG2\n224Ig7fdls6dO3P0Z4/lT7fdukaaj4/cl+7duwOw197/xvz6egDuunMS++9/IL1796ZXr17sv/+B\n3Dnpjja/hvZoxPBBPDtvEc/Pf5XlK1Zy06SpHDZy5zXSRAQbb9QVgE16dOPFha8DcNjInblp0lSW\nLV/B3AWv8uy8RYwYPqitL6Gw6qRcS624D7OGFiyYz4ABq8cH6N9/AI880vQ4plf+/nccPOqQ1ccO\nLDl2wAAWLJjfeoW19/Truwn1L6+uzc9/eTF7lQW9i389kdt+MYZTj/043bt14dCv/gyA/ptvwsOP\nP7/62FcW06/vJm1R7MJraJIXWZvVMCWtlDRd0hOSbpLUPdt+nqSZkmZk+/fOtt+bDS//mKQHJG3f\nVmVtKxGx1ramRmu5/n+vZeqjUzjzG99q8bFWXY01Ccu/jWNG7cm1tz3EkFHf4VOn/5Lfff8L6ftp\n5Dtq5Ktsp/I2yNtHk3xpROwaEcOBZcBXJe0DHAbsHhE7Awew5qCfx0fELsBVwGVtWNY20b//AOrr\nV1/u/Pn19OvXb610f7nnbi695GL+cMsEunTpsvrYeSXH1tez1VZrH2vVN/+VJQzYotd76/236MWC\nrMnd4IRP7sPNd04F4OEZz9G1cyf6bLpROnbLkmP79nqvud7u5Rx4o5b1glr1Yd4PDAG2Io1r9y+A\niFgUEQsaSf+3LP0GZc8RI5g9+xmef+45li1bxk03jOfQw9YcSGX6tGmM+dpX+MP/TaBv377vbT/w\noIO5++47Wbx4MYsXL+buu+/kwIMObutLaJemzJzLkK03Z5t+m9GpYweOPnh3/nzvjDXSzHvpNUbu\nlRpF2w/egq5dOrFw8Vv8+d4ZHH3w7nTu1JFt+m3GkK03Z/ITz9fgKoqpiiOut4o278OU1JE0MdEd\nwJ3ABZKeBu4GboiI+xo57HDg8UbyOgU4BWDg1lu3WplbS8eOHfnp5T/n8EMPZuXKlZxw4kkM++AH\nuejCC9h9jz057PAj+PY53+Ltt97i+GOPBtJ1/uGWCfTu3Ztzv/0dPrLPCAC+fd4F9O7du5aX026s\nXLmKMy+9kdt+cRod6sRVtz7Ek3Ne4junHsrUWS/w5/se55yf3MIvvjOa0z+3LxFw8gXXAPDknJe4\n+c5pTLv5PFasXMXXL7mRVavcJoeGPsxidyupsb6wVjmRtJLVQe9+4BsRsSyb3e2jwL7AV4BzIuLK\nbEDPrYClwPPA6RExb62MM3vssWc88HCzY39aAfUaMabWRbD36d3pYx+tMOp5i+y4027x+z/+NVfa\nfYb0quq582rLGubSiNi1fGNErATuJQ0V/zhwAnBltvv4SiMgm9mGo+hv+tT0saLszveqiHgm27Qr\nMLeZQ8xsA1bwFnnNn8PsAfxM0qbACmA2WZ+kmbU/BY+XbRcwI6JHI9seBT7URPqRrV0mMyuYgkfM\nWtcwzcyAhkeGih0xHTDNrBg8gLCZWX4OmGZmuXgSNDOz3FzDNDPLodbviefhgGlmxVHwiOmAaWaF\n4T5MM7OcPOK6mVkeeQfDzBlUJY3KZm2YLemcRvZ/VdLj2UwPf5c0rLF8SjlgmllhVGuKimzYyLGk\nsXeHAaMbCYjXRcRO2ShqPwR+UilfB0wzKwRR1Skq9gJmR8SciFgGjAeOLE0QEW+UrG7E2lMzrcV9\nmGZWGFXswuzPmvOD1QN7r3U+6TTgLKAzsF+lTF3DNLPiyN+H2UfSlJKlfFjIxmLvWjXIiBgbEdsB\nZwPnVyqea5hmVhgtmNNnUYUpKuqBgSXrA4DGJlhsMB74ZaWTuoZpZoVRxZvkk4GhkgZL6gwcC0xY\n41zS0JLVQ4FnqMA1TDMrjip1YkbECkljgElAB+CKiJgp6SJgSkRMAMZIOgBYDiwmzSfWLAdMMyuE\nag8gHBETgYll2y4o+fzvLc3TAdPMisEDCJuZ5VfweOmAaWYFUvCI6YBpZgWhljxWVBMOmGZWCB5A\n2MysJQoeMR0wzawwPICwmVlOBe/CdMA0s+IoeLx0wDSzghCo4FVMB0wzK4SGAYSLzAHTzAqj4PHS\nAdPMisM1TDOznPxYkZlZXsWOlw6YZlYMEtQ5YJqZ5eMmuZlZXsWOlw6YZlYcBY+XDphmVhx+rMjM\nLBe5D9PMLA+/Gmlm1gIOmGZmOblJbmaWh+clNzPLx5OgmZm1RMEjpgOmmRVG0fsw62pdADOzBnXK\nt+QhaZSkpyTNlnROI/vPkjRL0gxJ90japmL5Wn5JZmatRDmXStlIHYCxwCHAMGC0pGFlyaYBe0bE\nzsAfgB9WytcB08wKQzn/y2EvYHZEzImIZcB44MjSBBHx14h4J1t9CBhQKdMNpg9z6tRHF3XrpLm1\nLkcr6QMsqnUh7H3ZkL+7ik3Ylpg29dFJ3TurT87kXSVNKVkfFxHjStb7A/NK1uuBvZvJ70vA7ZVO\nusEEzIjYvNZlaC2SpkTEnrUuh7Wcv7v8ImJUFbNrrBoajSaUPgfsCXy8UqYbTMA0MytRDwwsWR8A\nLChPJOkA4Dzg4xHxr0qZug95EqoAAAAHXElEQVTTzDZEk4GhkgZL6gwcC0woTSBpN+DXwBER8Uqe\nTB0w1w/jKiexgvJ3VwMRsQIYA0wCngRujIiZki6SdESW7DKgB3CTpOmSJjSR3XsU0Wiz3szMyriG\naWaWkwOmmVlODphmZjk5YK5HpKKPFmi2YfNzmOuXjsDyhhVJCt+1KzRJ+wC9gFURcUety2PrxjXM\n9YSkfwNmSzpG0giAhmDpmmcxSRoF/I40AMSFki6sbYlsXTlgrj96AxuTRl65VNLZkraGFDgdNItF\n0seA/wFOiojTgdOBj0oaUtuS2bpwwFx/TAIeIX1npwCDSYHzEkldgM61LJytZVvgDeDNbP1x4HVg\nZc1KZOvMAbPAJO2UvdZFRKwEzgcGRMRs0sgqHwf2AP4KfE2S+6RrTNIekoZGxJXANcCPslfwLsiS\nvFCzwtk6c8AsKEmfAG4ADi7Z/DLQS9L3gB8AX46IA7PP12Wvg1mNZH2WNwDbSuoSEZcD9wC/BT4G\nHBcRKyX592495VcjC0jSfsCPgdMi4h9l+44n1VxOjojf1aJ8trbsbvgVwKkRcW/ZvtHAScA3gX/m\nGRXHislNuAIpeUxoFHB1RPxD0sak/spDSc3wu4D/Ihsc1Y8W1VbJz3834NaIuFdSr2z9IOA50h+4\nTqSBOL4OPFir8tq6ccAsll7Aa6Smd09JI4GTSb9sOwAfIv3SCThD0l0OljXX8GzsY8BRkr4KfBJY\nCGxFGg3nZxHxJUk9gfk1K6mtMzfJC0LSQaSa4xmkgU4vJj1C9BAwPiLuk3Q6sFtEnCRpQETU167E\nlg0++yVgOvAK8A5wGulphquAJ4BdgK9HxIk1KqZVkWuYxbE9sBPwn8CFEXG8pM0i4tWSmwSvk+Yy\n6eRgWVvZDZ6LSM3tvqTHiMYCB5b2UUraGRgoadOIWFKTwlrVOGAWx/WkX7p5wFmStoyIm7J9dZJO\nIA2IekJELG8qE2t9knoDE4EjI+K27AWCy4AhETEjS7MR6UbPScDnHCw3DH68oYYk7ZzVQCD1XS4j\nNcN/CXxO0meyfV/IlhMi4om2L6mViojXgMOBSyRtHBEvkPoxNweQ1IM0qdb+wOcjYmbNCmtV5T7M\nGpG0GenGQD1wFjCXNLH85aS5RzYFjiO9i3wb0DsiXq1Naa0xkg4hvf44CehHes7y3WxfF6BTRLxV\nwyJalTlg1lD2vOXdwPdJNZQdSXdRH4uIayV9kTRwwxcj4u3aldSakt34uRPYMiJekdQtIpbWulzW\nOhwwa0zS/qQHnncHjiLVKuuBLwJdSN/RG7UroVWS1TR/BOybd/ZBWz85YBZA9hrkpcA+EfGWpMER\n8Vyty2X5SToS+C6p7zL8fOyGyQGzILKg+WPgw9lNBb/Fs56R1MN9lhs2P1ZUEBExUVIn4G5JrqWs\nhxwsN3yuYRaMaylmxeWAaWaWkx9cNzPLyQHTzCwnB0wzs5wcMM3McnLAbGckrZQ0XdITkm6S1H0d\n8hop6U/Z5yMkndNM2k0lfe19nONCSd/Mu70szZWSjmrBuQZJ8uAm1iQHzPZnaUTsGhHDSaMjfbV0\np5IW/7uIiAkRcUkzSTYFWhwwzYrEAbN9ux8YktWsnpT0C2AqacDbgyQ9KGlqVhPtAWngXEn/lPR3\n4NMNGUk6UdLPs89bSLpF0mPZ8iHgEmC7rHZ7WZbuW5ImS5qRzYTZkNd5kp6SdDdpYOVmSTo5y+cx\nSTeX1ZoPkHS/pKclHZal7yDpspJzf2Vdf5DWPjhgtlNKc5gfAjyebdqeNPHabsDbpDnQD4iI3YEp\npEGNuwK/IY0F+VFgyyay/x/gvojYhTSoyEzgHODZrHb7rWxKjqHAXsCuwB6SPiZpD+BY0iRinwZG\n5Lic/4uIEdn5niRNG9FgEGn+9kOBX2XX8CXg9YgYkeV/sqTBOc5j7ZxfjWx/ukmann2+nzTeZj9g\nbkQ8lG3/N9JAxg9IAuhMmulwB+C5iHgGQNK1wCmNnGM/0oDHRMRK4PVsJsVSB2XLtGy9BymA9gRu\niYh3snNMyHFNwyV9n9Ts70Ean7LBjRGxCnhG0pzsGg4Cdi7p39wkO/fTOc5l7ZgDZvuzNCJ2Ld2Q\nBcXS8TYF3BURo8vS7QpU69UwAT+IiF+XnePr7+McVwKfjIjHJJ0IjCzZV55XZOc+PSJKAyuSBrXw\nvNbOuElujXkI+LCkIQCSukv6APBPYLCk7bJ0o5s4/h7g1OzYDkpzq79Jqj02mAScVNI32l9SX+Bv\nwKckdVOalvbwHOXtCbyYDV5yfNm+oyXVZWXeFngqO/epWXokfSCbg8esWa5h2loiYmFWU7s+m2oB\n4PyIeFrSKcCfJS0C/g4MbySLfwfGSfoSsBI4NSIelPRA9tjO7Vk/5o7Ag1kN9y3SZGFTJd1Amrp2\nLqnboJLvAA9n6R9nzcD8FHAfsAXw1Yh4V9JvSX2bU5VOvpA0l7hZszz4hplZTm6Sm5nl5IBpZpaT\nA6aZWU4OmGZmOTlgmpnl5IBpZpaTA6aZWU7/D+qjr6kck2/pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a9d18c8c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ACCURACY: 0.696\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_cv_acc</th>\n",
       "      <th>holdout_acc</th>\n",
       "      <th>validation_acc</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>variant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2018-07-14 21:27:36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>2018-07-14 23:08:11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2018-07-15 11:34:38</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2018-07-18 01:38:02</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>2018-07-18 01:52:35</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2018-07-25 12:41:00</td>\n",
       "      <td>2FOLDMCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>2018-07-25 12:57:30</td>\n",
       "      <td>10FOLDMCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>2018-07-25 13:15:29</td>\n",
       "      <td>10FOLDMCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>2018-07-25 14:53:19</td>\n",
       "      <td>10FOLDMCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>2018-07-25 22:50:36</td>\n",
       "      <td>10FOLDMCC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_cv_acc  holdout_acc  validation_acc        date_modified  \\\n",
       "model                                                                  \n",
       "ada       0.823529     0.863636        0.812500  2018-07-14 21:27:36   \n",
       "ada       1.000000     0.772727        0.562500  2018-07-14 23:08:11   \n",
       "ada       0.741176     0.636364        0.750000  2018-07-15 11:34:38   \n",
       "ada       0.823529     0.727273        0.700000  2018-07-18 01:38:02   \n",
       "ada       0.741176     0.636364        0.733333  2018-07-18 01:52:35   \n",
       "ada       0.811765     0.727273        0.750000  2018-07-25 12:41:00   \n",
       "ada       1.000000     0.863636        0.625000  2018-07-25 12:57:30   \n",
       "ada       1.000000     0.863636        0.739130  2018-07-25 13:15:29   \n",
       "ada       1.000000     0.818182        0.695652  2018-07-25 14:53:19   \n",
       "ada       1.000000     0.863636        0.695652  2018-07-25 22:50:36   \n",
       "\n",
       "         variant  \n",
       "model             \n",
       "ada          NaN  \n",
       "ada          NaN  \n",
       "ada          FSS  \n",
       "ada           V3  \n",
       "ada        FSSV3  \n",
       "ada     2FOLDMCC  \n",
       "ada    10FOLDMCC  \n",
       "ada    10FOLDMCC  \n",
       "ada    10FOLDMCC  \n",
       "ada    10FOLDMCC  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAGDCAYAAACFuAwbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a9d1ca08d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ml_utils as mu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cv = 10\n",
    "variant = '10FOLDMCC'\n",
    "\n",
    "groupings = [\n",
    "#     {'name': 'cvp', 'grouping':{0:0, 1:1, 2:1, 3:1}, 'description':'Control vs. All Parkinsons'},\n",
    "#     {'name': 'iva', 'grouping':{1:1, 2:2, 3:2},'description':'Idiopathic vs. Atypical Parkinsons'},\n",
    "    {'name': 'mvp', 'grouping':{2:2, 3:3},'description':'MSA vs. PSP'}\n",
    "]\n",
    "\n",
    "mods = mu.get_baseline_models()\n",
    "# mods = [x for x in mods if x['name'] not in ['svc_rbf']]\n",
    "mods = [x for x in mods if x['name'] in ['ada']]\n",
    "\n",
    "for grouping in groupings:\n",
    "    print(\"===================================================================================\")\n",
    "    print(\"====\")\n",
    "    print(\"====\")\n",
    "    print(\"====                         Starting %s\" %grouping['description'])\n",
    "    if variant: print(\"====                                      %s\" %variant)\n",
    "    print(\"====\")\n",
    "    print(\"====\")\n",
    "    print(\"===================================================================================\")\n",
    "    with mu.HiddenPrints():\n",
    "        X, y , Xh, yh, Xv, yv = mu.get_training_holdout_validation_data(grouping['grouping'], resample=False, use_v3=True)\n",
    "\n",
    "    results_file = 'gridCV_%s.csv'%(grouping['name'])\n",
    "    if variant:\n",
    "        plot_file = '%s_%s_accuracy.png' %(results_file.split('.')[0], variant)\n",
    "    else:\n",
    "        plot_file = '%s_accuracy.png' %(results_file.split('.')[0])\n",
    "    \n",
    "    for m in mods:\n",
    "        mod_clf = m['model']\n",
    "        mod_name = m['name']\n",
    "        params = m['params']\n",
    "\n",
    "        if mod_name == 'knn':\n",
    "            params['classifier__n_neighbors'] = np.linspace(5,round((1 - 1.0/cv)*len(y) - 5),10, dtype = int)\n",
    "        \n",
    "        accuracy = do_grid_search(mod_clf, mod_name, params, cv=cv, variant=variant, scoring=metrics.make_scorer(metrics.matthews_corrcoef), group=grouping)\n",
    "        df = addData(accuracy, data_file = results_file)\n",
    "        showData(df, mod_name)\n",
    "\n",
    "    plot_results(title=grouping['description'], data_file=results_file, plot_file=plot_file, variant=variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_cv_acc</th>\n",
       "      <th>holdout_acc</th>\n",
       "      <th>validation_acc</th>\n",
       "      <th>cv</th>\n",
       "      <th>best_params</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>variant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 60, 'classifier__p...</td>\n",
       "      <td>2018-07-14 19:24:35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.969799</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.9952623149688795}</td>\n",
       "      <td>2018-07-14 19:24:43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svc_rbf</td>\n",
       "      <td>0.963087</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1291549.6650148828, 'classif...</td>\n",
       "      <td>2018-07-14 19:24:55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.971477</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-14 19:25:49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.944631</td>\n",
       "      <td>0.906863</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.01487352107293...</td>\n",
       "      <td>2018-07-14 19:26:33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.845638</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None}</td>\n",
       "      <td>2018-07-14 19:26:35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>log</td>\n",
       "      <td>0.963087</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-14 19:26:44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ann</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'tanh', 'classifier...</td>\n",
       "      <td>2018-07-14 19:41:32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.017782794100389229, 'c...</td>\n",
       "      <td>2018-07-14 19:41:47</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.946309</td>\n",
       "      <td>0.887255</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 5, 'classifier__p'...</td>\n",
       "      <td>2018-07-14 23:45:50</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.944631</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 37, 'classifier__p...</td>\n",
       "      <td>2018-07-15 00:16:21</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.964765</td>\n",
       "      <td>0.936275</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 2.8183829312644537, 'kbest__...</td>\n",
       "      <td>2018-07-15 00:16:29</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.941275</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 5, 'classifier__p'...</td>\n",
       "      <td>2018-07-15 10:17:10</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.958054</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'kbest__k': 20}</td>\n",
       "      <td>2018-07-15 10:17:13</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.956376</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 5, 'classifier__p'...</td>\n",
       "      <td>2018-07-15 11:20:52</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.954698</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 5.6234132519034912, 'kbest__...</td>\n",
       "      <td>2018-07-15 11:24:06</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.944631</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.00012689610031...</td>\n",
       "      <td>2018-07-15 11:28:53</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.929530</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None, 'kbest__k': 1}</td>\n",
       "      <td>2018-07-15 11:28:59</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>log</td>\n",
       "      <td>0.942953</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 17.433288221999881, 'classif...</td>\n",
       "      <td>2018-07-15 11:29:08</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.976510</td>\n",
       "      <td>0.936275</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-15 11:44:41</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ann</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'tanh', 'classifier...</td>\n",
       "      <td>2018-07-15 13:17:14</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.056234132519034911, 'c...</td>\n",
       "      <td>2018-07-15 13:17:46</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.944631</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.01487352107293...</td>\n",
       "      <td>2018-07-18 01:37:56</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ann</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946078</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'tanh', 'classifier...</td>\n",
       "      <td>2018-07-18 01:37:57</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.845638</td>\n",
       "      <td>0.789216</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None}</td>\n",
       "      <td>2018-07-18 01:37:57</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>knn</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 60, 'classifier__p...</td>\n",
       "      <td>2018-07-18 01:37:57</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>log</td>\n",
       "      <td>0.963087</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-18 01:37:57</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.971477</td>\n",
       "      <td>0.906863</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-18 01:37:58</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.969799</td>\n",
       "      <td>0.936275</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.9952623149688795}</td>\n",
       "      <td>2018-07-18 01:37:58</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>svc_rbf</td>\n",
       "      <td>0.963087</td>\n",
       "      <td>0.946078</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1291549.6650148828, 'classif...</td>\n",
       "      <td>2018-07-18 01:37:58</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.964765</td>\n",
       "      <td>0.936275</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 2.8183829312644537, 'kbest__...</td>\n",
       "      <td>2018-07-18 01:52:31</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.056234132519034911, 'c...</td>\n",
       "      <td>2018-07-18 01:52:32</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.590604</td>\n",
       "      <td>0.642157</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None, 'pca__n_component...</td>\n",
       "      <td>2018-07-18 02:52:04</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.597315</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None, 'pca__n_component...</td>\n",
       "      <td>2018-07-18 02:55:37</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>knn</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 69, 'classifier__p...</td>\n",
       "      <td>2018-07-18 02:57:38</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.696309</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 3.9810717055349722, 'pca__n_...</td>\n",
       "      <td>2018-07-18 02:57:46</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>log</td>\n",
       "      <td>0.958054</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'classifier__C': 92367.085718738657, 'classif...</td>\n",
       "      <td>2018-07-20 17:36:34</td>\n",
       "      <td>5FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.976510</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-20 17:42:29</td>\n",
       "      <td>5FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>log</td>\n",
       "      <td>0.963087</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'classifier__C': 1.6102620275609394, 'classif...</td>\n",
       "      <td>2018-07-20 17:42:40</td>\n",
       "      <td>5FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.973154</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-20 21:05:16</td>\n",
       "      <td>5FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>log</td>\n",
       "      <td>0.959732</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-20 21:05:25</td>\n",
       "      <td>5FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ann</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'classifier__activation': 'logistic', 'classi...</td>\n",
       "      <td>2018-07-20 21:47:26</td>\n",
       "      <td>5FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.974832</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-20 23:11:57</td>\n",
       "      <td>10FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>log</td>\n",
       "      <td>0.961409</td>\n",
       "      <td>0.946078</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-20 23:12:06</td>\n",
       "      <td>10FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ann</td>\n",
       "      <td>0.988255</td>\n",
       "      <td>0.936275</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'classifier__activation': 'logistic', 'classi...</td>\n",
       "      <td>2018-07-21 00:46:55</td>\n",
       "      <td>10FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.973154</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>20.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-21 12:22:00</td>\n",
       "      <td>20FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>log</td>\n",
       "      <td>0.969799</td>\n",
       "      <td>0.936275</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>20.0</td>\n",
       "      <td>{'classifier__C': 1.6102620275609394, 'classif...</td>\n",
       "      <td>2018-07-21 12:22:12</td>\n",
       "      <td>20FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ann</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946078</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>20.0</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>2018-07-21 15:42:09</td>\n",
       "      <td>20FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.968121</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-21 23:33:04</td>\n",
       "      <td>30FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>log</td>\n",
       "      <td>0.958054</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{'classifier__C': 2.5929437974046672, 'classif...</td>\n",
       "      <td>2018-07-21 23:33:18</td>\n",
       "      <td>30FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ann</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>2018-07-22 04:33:02</td>\n",
       "      <td>30FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.944631</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.01487352107293...</td>\n",
       "      <td>2018-07-25 12:00:01</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ann</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'tanh', 'classifier...</td>\n",
       "      <td>2018-07-25 12:00:02</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.845638</td>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None}</td>\n",
       "      <td>2018-07-25 12:00:02</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>knn</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 60, 'classifier__p...</td>\n",
       "      <td>2018-07-25 12:00:02</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>log</td>\n",
       "      <td>0.963087</td>\n",
       "      <td>0.946078</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-25 12:00:02</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.971477</td>\n",
       "      <td>0.946078</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-25 12:00:02</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.969799</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.9952623149688795}</td>\n",
       "      <td>2018-07-25 12:00:02</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>svc_rbf</td>\n",
       "      <td>0.963087</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1291549.6650148828, 'classif...</td>\n",
       "      <td>2018-07-25 12:00:02</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.017782794100389229, 'c...</td>\n",
       "      <td>2018-07-25 12:00:02</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  mean_cv_acc  holdout_acc  validation_acc    cv  \\\n",
       "0        knn     1.000000     0.750000        0.829545   2.0   \n",
       "1    svc_lin     0.969799     0.911765        0.977273   2.0   \n",
       "2    svc_rbf     0.963087     0.897059        0.977273   2.0   \n",
       "3   rand_for     0.971477     0.911765        0.988636   2.0   \n",
       "4        ada     0.944631     0.906863        0.988636   2.0   \n",
       "5        gnb     0.845638     0.794118        0.943182   2.0   \n",
       "6        log     0.963087     0.911765        0.988636   2.0   \n",
       "7        ann     1.000000     0.931373        0.988636   2.0   \n",
       "8    xgboost     1.000000     0.926471        0.988636   2.0   \n",
       "9        knn     0.946309     0.887255        0.795455   2.0   \n",
       "10       knn     0.944631     0.921569        0.988636   2.0   \n",
       "11   svc_lin     0.964765     0.936275        0.988636   2.0   \n",
       "12       knn     0.941275     0.862745        0.795455   2.0   \n",
       "13   svc_lin     0.958054     0.921569        0.988636   2.0   \n",
       "14       knn     0.956376     0.867647        0.829545   2.0   \n",
       "15   svc_lin     0.954698     0.926471        0.988636   2.0   \n",
       "16       ada     0.944631     0.916667        0.988636   2.0   \n",
       "17       gnb     0.929530     0.911765        0.988636   2.0   \n",
       "18       log     0.942953     0.931373        0.988636   2.0   \n",
       "19  rand_for     0.976510     0.936275        0.988636   2.0   \n",
       "20       ann     1.000000     0.960784        0.988636   2.0   \n",
       "21   xgboost     1.000000     0.960784        0.909091   2.0   \n",
       "22       ada     0.944631     0.916667        0.941667   2.0   \n",
       "23       ann     1.000000     0.946078        0.933333   2.0   \n",
       "24       gnb     0.845638     0.789216        0.900000   2.0   \n",
       "25       knn     1.000000     0.848039        0.800000   2.0   \n",
       "26       log     0.963087     0.921569        0.958333   2.0   \n",
       "27  rand_for     0.971477     0.906863        0.941667   2.0   \n",
       "28   svc_lin     0.969799     0.936275        0.941667   2.0   \n",
       "29   svc_rbf     0.963087     0.946078        0.958333   2.0   \n",
       "..       ...          ...          ...             ...   ...   \n",
       "37   svc_lin     0.964765     0.936275        0.875000   2.0   \n",
       "38   xgboost     1.000000     0.941176        0.916667   2.0   \n",
       "39       gnb     0.590604     0.642157        0.613636   2.0   \n",
       "40       gnb     0.597315     0.656863        0.670455   2.0   \n",
       "41       knn     1.000000     0.691176        0.670455   2.0   \n",
       "42   svc_lin     0.696309     0.735294        0.613636   2.0   \n",
       "43       log     0.958054     0.941176        0.988636   5.0   \n",
       "44  rand_for     0.976510     0.921569        0.988636   5.0   \n",
       "45       log     0.963087     0.926471        0.988636   5.0   \n",
       "46  rand_for     0.973154     0.931373        0.988636   5.0   \n",
       "47       log     0.959732     0.931373        0.988636   5.0   \n",
       "48       ann     1.000000     0.941176        0.988636   5.0   \n",
       "49  rand_for     0.974832     0.931373        0.988636  10.0   \n",
       "50       log     0.961409     0.946078        0.988636  10.0   \n",
       "51       ann     0.988255     0.936275        0.977273  10.0   \n",
       "52  rand_for     0.973154     0.921569        0.988636  20.0   \n",
       "53       log     0.969799     0.936275        0.988636  20.0   \n",
       "54       ann     1.000000     0.946078        0.988636  20.0   \n",
       "55  rand_for     0.968121     0.911765        0.988636  30.0   \n",
       "56       log     0.958054     0.921569        0.988636  30.0   \n",
       "57       ann     1.000000     0.926471        0.988636  30.0   \n",
       "58       ada     0.944631     0.941176        0.933333   2.0   \n",
       "59       ann     1.000000     0.950980        0.908333   2.0   \n",
       "60       gnb     0.845638     0.848039        0.916667   2.0   \n",
       "61       knn     1.000000     0.843137        0.833333   2.0   \n",
       "62       log     0.963087     0.946078        0.966667   2.0   \n",
       "63  rand_for     0.971477     0.946078        0.925000   2.0   \n",
       "64   svc_lin     0.969799     0.941176        0.958333   2.0   \n",
       "65   svc_rbf     0.963087     0.931373        0.958333   2.0   \n",
       "66   xgboost     1.000000     0.950980        0.933333   2.0   \n",
       "\n",
       "                                          best_params        date_modified  \\\n",
       "0   {'classifier__n_neighbors': 60, 'classifier__p...  2018-07-14 19:24:35   \n",
       "1               {'classifier__C': 1.9952623149688795}  2018-07-14 19:24:43   \n",
       "2   {'classifier__C': 1291549.6650148828, 'classif...  2018-07-14 19:24:55   \n",
       "3   {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-14 19:25:49   \n",
       "4   {'classifier__learning_rate': 0.01487352107293...  2018-07-14 19:26:33   \n",
       "5                        {'classifier__priors': None}  2018-07-14 19:26:35   \n",
       "6   {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-14 19:26:44   \n",
       "7   {'classifier__activation': 'tanh', 'classifier...  2018-07-14 19:41:32   \n",
       "8   {'classifier__gamma': 0.017782794100389229, 'c...  2018-07-14 19:41:47   \n",
       "9   {'classifier__n_neighbors': 5, 'classifier__p'...  2018-07-14 23:45:50   \n",
       "10  {'classifier__n_neighbors': 37, 'classifier__p...  2018-07-15 00:16:21   \n",
       "11  {'classifier__C': 2.8183829312644537, 'kbest__...  2018-07-15 00:16:29   \n",
       "12  {'classifier__n_neighbors': 5, 'classifier__p'...  2018-07-15 10:17:10   \n",
       "13             {'classifier__C': 1.0, 'kbest__k': 20}  2018-07-15 10:17:13   \n",
       "14  {'classifier__n_neighbors': 5, 'classifier__p'...  2018-07-15 11:20:52   \n",
       "15  {'classifier__C': 5.6234132519034912, 'kbest__...  2018-07-15 11:24:06   \n",
       "16  {'classifier__learning_rate': 0.00012689610031...  2018-07-15 11:28:53   \n",
       "17        {'classifier__priors': None, 'kbest__k': 1}  2018-07-15 11:28:59   \n",
       "18  {'classifier__C': 17.433288221999881, 'classif...  2018-07-15 11:29:08   \n",
       "19  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-15 11:44:41   \n",
       "20  {'classifier__activation': 'tanh', 'classifier...  2018-07-15 13:17:14   \n",
       "21  {'classifier__gamma': 0.056234132519034911, 'c...  2018-07-15 13:17:46   \n",
       "22  {'classifier__learning_rate': 0.01487352107293...  2018-07-18 01:37:56   \n",
       "23  {'classifier__activation': 'tanh', 'classifier...  2018-07-18 01:37:57   \n",
       "24                       {'classifier__priors': None}  2018-07-18 01:37:57   \n",
       "25  {'classifier__n_neighbors': 60, 'classifier__p...  2018-07-18 01:37:57   \n",
       "26  {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-18 01:37:57   \n",
       "27  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-18 01:37:58   \n",
       "28              {'classifier__C': 1.9952623149688795}  2018-07-18 01:37:58   \n",
       "29  {'classifier__C': 1291549.6650148828, 'classif...  2018-07-18 01:37:58   \n",
       "..                                                ...                  ...   \n",
       "37  {'classifier__C': 2.8183829312644537, 'kbest__...  2018-07-18 01:52:31   \n",
       "38  {'classifier__gamma': 0.056234132519034911, 'c...  2018-07-18 01:52:32   \n",
       "39  {'classifier__priors': None, 'pca__n_component...  2018-07-18 02:52:04   \n",
       "40  {'classifier__priors': None, 'pca__n_component...  2018-07-18 02:55:37   \n",
       "41  {'classifier__n_neighbors': 69, 'classifier__p...  2018-07-18 02:57:38   \n",
       "42  {'classifier__C': 3.9810717055349722, 'pca__n_...  2018-07-18 02:57:46   \n",
       "43  {'classifier__C': 92367.085718738657, 'classif...  2018-07-20 17:36:34   \n",
       "44  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-20 17:42:29   \n",
       "45  {'classifier__C': 1.6102620275609394, 'classif...  2018-07-20 17:42:40   \n",
       "46  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-20 21:05:16   \n",
       "47  {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-20 21:05:25   \n",
       "48  {'classifier__activation': 'logistic', 'classi...  2018-07-20 21:47:26   \n",
       "49  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-20 23:11:57   \n",
       "50  {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-20 23:12:06   \n",
       "51  {'classifier__activation': 'logistic', 'classi...  2018-07-21 00:46:55   \n",
       "52  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-21 12:22:00   \n",
       "53  {'classifier__C': 1.6102620275609394, 'classif...  2018-07-21 12:22:12   \n",
       "54  {'classifier__activation': 'relu', 'classifier...  2018-07-21 15:42:09   \n",
       "55  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-21 23:33:04   \n",
       "56  {'classifier__C': 2.5929437974046672, 'classif...  2018-07-21 23:33:18   \n",
       "57  {'classifier__activation': 'relu', 'classifier...  2018-07-22 04:33:02   \n",
       "58  {'classifier__learning_rate': 0.01487352107293...  2018-07-25 12:00:01   \n",
       "59  {'classifier__activation': 'tanh', 'classifier...  2018-07-25 12:00:02   \n",
       "60                       {'classifier__priors': None}  2018-07-25 12:00:02   \n",
       "61  {'classifier__n_neighbors': 60, 'classifier__p...  2018-07-25 12:00:02   \n",
       "62  {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-25 12:00:02   \n",
       "63  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-25 12:00:02   \n",
       "64              {'classifier__C': 1.9952623149688795}  2018-07-25 12:00:02   \n",
       "65  {'classifier__C': 1291549.6650148828, 'classif...  2018-07-25 12:00:02   \n",
       "66  {'classifier__gamma': 0.017782794100389229, 'c...  2018-07-25 12:00:02   \n",
       "\n",
       "   variant  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  \n",
       "5      NaN  \n",
       "6      NaN  \n",
       "7      NaN  \n",
       "8      NaN  \n",
       "9      FSS  \n",
       "10     FSS  \n",
       "11     FSS  \n",
       "12     FSS  \n",
       "13     FSS  \n",
       "14     FSS  \n",
       "15     FSS  \n",
       "16     FSS  \n",
       "17     FSS  \n",
       "18     FSS  \n",
       "19     FSS  \n",
       "20     FSS  \n",
       "21     FSS  \n",
       "22      V3  \n",
       "23      V3  \n",
       "24      V3  \n",
       "25      V3  \n",
       "26      V3  \n",
       "27      V3  \n",
       "28      V3  \n",
       "29      V3  \n",
       "..     ...  \n",
       "37   FSSV3  \n",
       "38   FSSV3  \n",
       "39     PCA  \n",
       "40     PCA  \n",
       "41     PCA  \n",
       "42     PCA  \n",
       "43   5FOLD  \n",
       "44   5FOLD  \n",
       "45   5FOLD  \n",
       "46   5FOLD  \n",
       "47   5FOLD  \n",
       "48   5FOLD  \n",
       "49  10FOLD  \n",
       "50  10FOLD  \n",
       "51  10FOLD  \n",
       "52  20FOLD  \n",
       "53  20FOLD  \n",
       "54  20FOLD  \n",
       "55  30FOLD  \n",
       "56  30FOLD  \n",
       "57  30FOLD  \n",
       "58      V3  \n",
       "59      V3  \n",
       "60      V3  \n",
       "61      V3  \n",
       "62      V3  \n",
       "63      V3  \n",
       "64      V3  \n",
       "65      V3  \n",
       "66      V3  \n",
       "\n",
       "[67 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtbricker\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_cv_acc</th>\n",
       "      <th>holdout_acc</th>\n",
       "      <th>validation_acc</th>\n",
       "      <th>cv</th>\n",
       "      <th>best_params</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>variant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.898515</td>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 60, 'classifier__p...</td>\n",
       "      <td>2018-07-14 19:42:10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.9952623149688795}</td>\n",
       "      <td>2018-07-14 19:42:20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svc_rbf</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 0.27825594022071259, 'classi...</td>\n",
       "      <td>2018-07-14 19:42:30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.995050</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-14 19:43:21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.918317</td>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.01487352107293...</td>\n",
       "      <td>2018-07-14 19:44:01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.878713</td>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None}</td>\n",
       "      <td>2018-07-14 19:44:03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>log</td>\n",
       "      <td>0.896040</td>\n",
       "      <td>0.83750</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.6102620275609394, 'classif...</td>\n",
       "      <td>2018-07-14 19:44:12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ann</td>\n",
       "      <td>0.950495</td>\n",
       "      <td>0.86875</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>2018-07-14 19:59:19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.031622776601683791, 'c...</td>\n",
       "      <td>2018-07-14 19:59:33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.913366</td>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 26, 'classifier__p...</td>\n",
       "      <td>2018-07-14 23:47:09</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>knn</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.67500</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 69, 'classifier__p...</td>\n",
       "      <td>2018-07-15 11:21:41</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.83125</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 2.8183829312644537, 'kbest__...</td>\n",
       "      <td>2018-07-15 11:24:13</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.955446</td>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.07880462815669...</td>\n",
       "      <td>2018-07-15 11:32:02</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.876238</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None, 'kbest__k': 37}</td>\n",
       "      <td>2018-07-15 11:32:09</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>log</td>\n",
       "      <td>0.863861</td>\n",
       "      <td>0.77500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 17.433288221999881, 'classif...</td>\n",
       "      <td>2018-07-15 11:32:19</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.977723</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-15 13:22:23</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ann</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73125</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>2018-07-15 14:52:20</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.10000000000000001, 'cl...</td>\n",
       "      <td>2018-07-15 14:52:47</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.918317</td>\n",
       "      <td>0.83125</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.01487352107293...</td>\n",
       "      <td>2018-07-18 01:37:59</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ann</td>\n",
       "      <td>0.950495</td>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>2018-07-18 01:38:01</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.878713</td>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None}</td>\n",
       "      <td>2018-07-18 01:38:01</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.898515</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 60, 'classifier__p...</td>\n",
       "      <td>2018-07-18 01:38:01</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>log</td>\n",
       "      <td>0.896040</td>\n",
       "      <td>0.83750</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.6102620275609394, 'classif...</td>\n",
       "      <td>2018-07-18 01:38:01</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.995050</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-18 01:38:01</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.9952623149688795}</td>\n",
       "      <td>2018-07-18 01:38:01</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>svc_rbf</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 0.27825594022071259, 'classi...</td>\n",
       "      <td>2018-07-18 01:38:01</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.031622776601683791, 'c...</td>\n",
       "      <td>2018-07-18 01:38:01</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.955446</td>\n",
       "      <td>0.82500</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.07880462815669...</td>\n",
       "      <td>2018-07-18 01:52:32</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ann</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>2018-07-18 01:52:34</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.876238</td>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None, 'kbest__k': 37}</td>\n",
       "      <td>2018-07-18 01:52:34</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.977723</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-18 01:52:34</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.81875</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 2.8183829312644537, 'kbest__...</td>\n",
       "      <td>2018-07-18 01:52:34</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.10000000000000001, 'cl...</td>\n",
       "      <td>2018-07-18 01:52:34</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.78750</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None, 'pca__n_component...</td>\n",
       "      <td>2018-07-18 02:52:12</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.876238</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None, 'pca__n_component...</td>\n",
       "      <td>2018-07-18 02:55:44</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>log</td>\n",
       "      <td>0.898515</td>\n",
       "      <td>0.83750</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'classifier__C': 2.5929437974046672, 'classif...</td>\n",
       "      <td>2018-07-20 17:36:44</td>\n",
       "      <td>5FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.982673</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-20 21:49:00</td>\n",
       "      <td>5FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>log</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.85625</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'classifier__C': 1.6102620275609394, 'classif...</td>\n",
       "      <td>2018-07-20 21:49:08</td>\n",
       "      <td>5FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ann</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'classifier__activation': 'logistic', 'classi...</td>\n",
       "      <td>2018-07-20 22:25:58</td>\n",
       "      <td>5FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 4, 'classifie...</td>\n",
       "      <td>2018-07-21 00:50:03</td>\n",
       "      <td>10FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>log</td>\n",
       "      <td>0.896040</td>\n",
       "      <td>0.86875</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'classifier__C': 13738.237958832638, 'classif...</td>\n",
       "      <td>2018-07-21 00:50:13</td>\n",
       "      <td>10FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ann</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.85000</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>2018-07-21 02:09:13</td>\n",
       "      <td>10FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.987624</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>20.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 4, 'classifie...</td>\n",
       "      <td>2018-07-21 15:48:24</td>\n",
       "      <td>20FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>log</td>\n",
       "      <td>0.908416</td>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>20.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-21 15:48:36</td>\n",
       "      <td>20FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ann</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.81875</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>20.0</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>2018-07-21 18:11:39</td>\n",
       "      <td>20FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.987624</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-22 04:42:08</td>\n",
       "      <td>30FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>log</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{'classifier__C': 4.1753189365604015, 'classif...</td>\n",
       "      <td>2018-07-22 04:42:21</td>\n",
       "      <td>30FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ann</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>2018-07-22 08:35:18</td>\n",
       "      <td>30FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.81875</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-25 11:21:22</td>\n",
       "      <td>2FOLDMCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>log</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.88125</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-25 11:21:31</td>\n",
       "      <td>2FOLDMCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ann</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>2018-07-25 11:25:49</td>\n",
       "      <td>2FOLDMCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.918317</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.01487352107293...</td>\n",
       "      <td>2018-07-25 12:00:03</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ann</td>\n",
       "      <td>0.950495</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>2018-07-25 12:00:05</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.878713</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None}</td>\n",
       "      <td>2018-07-25 12:00:05</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.898515</td>\n",
       "      <td>0.77500</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 60, 'classifier__p...</td>\n",
       "      <td>2018-07-25 12:00:05</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>log</td>\n",
       "      <td>0.896040</td>\n",
       "      <td>0.85625</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.6102620275609394, 'classif...</td>\n",
       "      <td>2018-07-25 12:00:05</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.995050</td>\n",
       "      <td>0.73125</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-25 12:00:05</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.88750</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.9952623149688795}</td>\n",
       "      <td>2018-07-25 12:00:06</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>svc_rbf</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.70000</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 0.27825594022071259, 'classi...</td>\n",
       "      <td>2018-07-25 12:00:06</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.031622776601683791, 'c...</td>\n",
       "      <td>2018-07-25 12:00:06</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  mean_cv_acc  holdout_acc  validation_acc    cv  \\\n",
       "0        knn     0.898515      0.80625        0.859375   2.0   \n",
       "1    svc_lin     0.891089      0.79375        0.828125   2.0   \n",
       "2    svc_rbf     0.900990      0.78125        0.921875   2.0   \n",
       "3   rand_for     0.995050      0.80000        0.875000   2.0   \n",
       "4        ada     0.918317      0.80625        0.968750   2.0   \n",
       "5        gnb     0.878713      0.80625        0.937500   2.0   \n",
       "6        log     0.896040      0.83750        0.859375   2.0   \n",
       "7        ann     0.950495      0.86875        0.859375   2.0   \n",
       "8    xgboost     1.000000      0.78125        0.937500   2.0   \n",
       "9        knn     0.913366      0.73750        0.812500   2.0   \n",
       "10       knn     1.000000      0.67500        0.687500   2.0   \n",
       "11   svc_lin     0.891089      0.83125        0.796875   2.0   \n",
       "12       ada     0.955446      0.80625        0.906250   2.0   \n",
       "13       gnb     0.876238      0.79375        0.906250   2.0   \n",
       "14       log     0.863861      0.77500        0.937500   2.0   \n",
       "15  rand_for     0.977723      0.75625        0.859375   2.0   \n",
       "16       ann     1.000000      0.73125        0.796875   2.0   \n",
       "17   xgboost     1.000000      0.75625        0.796875   2.0   \n",
       "18       ada     0.918317      0.83125        0.878378   2.0   \n",
       "19       ann     0.950495      0.80625        0.824324   2.0   \n",
       "20       gnb     0.878713      0.80625        0.891892   2.0   \n",
       "21       knn     0.898515      0.78125        0.824324   2.0   \n",
       "22       log     0.896040      0.83750        0.851351   2.0   \n",
       "23  rand_for     0.995050      0.79375        0.864865   2.0   \n",
       "24   svc_lin     0.891089      0.81250        0.837838   2.0   \n",
       "25   svc_rbf     0.900990      0.79375        0.891892   2.0   \n",
       "26   xgboost     1.000000      0.81250        0.891892   2.0   \n",
       "27       ada     0.955446      0.82500        0.824324   2.0   \n",
       "28       ann     1.000000      0.81250        0.743243   2.0   \n",
       "29       gnb     0.876238      0.81250        0.824324   2.0   \n",
       "..       ...          ...          ...             ...   ...   \n",
       "32  rand_for     0.977723      0.79375        0.824324   2.0   \n",
       "33   svc_lin     0.891089      0.81875        0.824324   2.0   \n",
       "34   xgboost     1.000000      0.79375        0.797297   2.0   \n",
       "35       gnb     0.891089      0.78750        0.875000   2.0   \n",
       "36       gnb     0.876238      0.78125        0.906250   2.0   \n",
       "37       log     0.898515      0.83750        0.796875   5.0   \n",
       "38  rand_for     0.982673      0.76250        0.812500   5.0   \n",
       "39       log     0.900990      0.85625        0.750000   5.0   \n",
       "40       ann     1.000000      0.76250        0.703125   5.0   \n",
       "41  rand_for     0.980198      0.80625        0.921875  10.0   \n",
       "42       log     0.896040      0.86875        0.828125  10.0   \n",
       "43       ann     1.000000      0.85000        0.828125  10.0   \n",
       "44  rand_for     0.987624      0.75000        0.843750  20.0   \n",
       "45       log     0.908416      0.81250        0.718750  20.0   \n",
       "46       ann     1.000000      0.81875        0.765625  20.0   \n",
       "47  rand_for     0.987624      0.79375        0.828125  30.0   \n",
       "48       log     0.900990      0.79375        0.734375  30.0   \n",
       "49       ann     1.000000      0.84375        0.734375  30.0   \n",
       "50  rand_for     0.990099      0.81875        0.812500   2.0   \n",
       "51       log     0.900990      0.88125        0.796875   2.0   \n",
       "52       ann     1.000000      0.80000        0.796875   2.0   \n",
       "53       ada     0.918317      0.78125        0.864865   2.0   \n",
       "54       ann     0.950495      0.80000        0.783784   2.0   \n",
       "55       gnb     0.878713      0.76250        0.797297   2.0   \n",
       "56       knn     0.898515      0.77500        0.783784   2.0   \n",
       "57       log     0.896040      0.85625        0.864865   2.0   \n",
       "58  rand_for     0.995050      0.73125        0.797297   2.0   \n",
       "59   svc_lin     0.891089      0.88750        0.837838   2.0   \n",
       "60   svc_rbf     0.900990      0.70000        0.756757   2.0   \n",
       "61   xgboost     1.000000      0.75625        0.837838   2.0   \n",
       "\n",
       "                                          best_params        date_modified  \\\n",
       "0   {'classifier__n_neighbors': 60, 'classifier__p...  2018-07-14 19:42:10   \n",
       "1               {'classifier__C': 1.9952623149688795}  2018-07-14 19:42:20   \n",
       "2   {'classifier__C': 0.27825594022071259, 'classi...  2018-07-14 19:42:30   \n",
       "3   {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-14 19:43:21   \n",
       "4   {'classifier__learning_rate': 0.01487352107293...  2018-07-14 19:44:01   \n",
       "5                        {'classifier__priors': None}  2018-07-14 19:44:03   \n",
       "6   {'classifier__C': 1.6102620275609394, 'classif...  2018-07-14 19:44:12   \n",
       "7   {'classifier__activation': 'relu', 'classifier...  2018-07-14 19:59:19   \n",
       "8   {'classifier__gamma': 0.031622776601683791, 'c...  2018-07-14 19:59:33   \n",
       "9   {'classifier__n_neighbors': 26, 'classifier__p...  2018-07-14 23:47:09   \n",
       "10  {'classifier__n_neighbors': 69, 'classifier__p...  2018-07-15 11:21:41   \n",
       "11  {'classifier__C': 2.8183829312644537, 'kbest__...  2018-07-15 11:24:13   \n",
       "12  {'classifier__learning_rate': 0.07880462815669...  2018-07-15 11:32:02   \n",
       "13       {'classifier__priors': None, 'kbest__k': 37}  2018-07-15 11:32:09   \n",
       "14  {'classifier__C': 17.433288221999881, 'classif...  2018-07-15 11:32:19   \n",
       "15  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-15 13:22:23   \n",
       "16  {'classifier__activation': 'relu', 'classifier...  2018-07-15 14:52:20   \n",
       "17  {'classifier__gamma': 0.10000000000000001, 'cl...  2018-07-15 14:52:47   \n",
       "18  {'classifier__learning_rate': 0.01487352107293...  2018-07-18 01:37:59   \n",
       "19  {'classifier__activation': 'relu', 'classifier...  2018-07-18 01:38:01   \n",
       "20                       {'classifier__priors': None}  2018-07-18 01:38:01   \n",
       "21  {'classifier__n_neighbors': 60, 'classifier__p...  2018-07-18 01:38:01   \n",
       "22  {'classifier__C': 1.6102620275609394, 'classif...  2018-07-18 01:38:01   \n",
       "23  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-18 01:38:01   \n",
       "24              {'classifier__C': 1.9952623149688795}  2018-07-18 01:38:01   \n",
       "25  {'classifier__C': 0.27825594022071259, 'classi...  2018-07-18 01:38:01   \n",
       "26  {'classifier__gamma': 0.031622776601683791, 'c...  2018-07-18 01:38:01   \n",
       "27  {'classifier__learning_rate': 0.07880462815669...  2018-07-18 01:52:32   \n",
       "28  {'classifier__activation': 'relu', 'classifier...  2018-07-18 01:52:34   \n",
       "29       {'classifier__priors': None, 'kbest__k': 37}  2018-07-18 01:52:34   \n",
       "..                                                ...                  ...   \n",
       "32  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-18 01:52:34   \n",
       "33  {'classifier__C': 2.8183829312644537, 'kbest__...  2018-07-18 01:52:34   \n",
       "34  {'classifier__gamma': 0.10000000000000001, 'cl...  2018-07-18 01:52:34   \n",
       "35  {'classifier__priors': None, 'pca__n_component...  2018-07-18 02:52:12   \n",
       "36  {'classifier__priors': None, 'pca__n_component...  2018-07-18 02:55:44   \n",
       "37  {'classifier__C': 2.5929437974046672, 'classif...  2018-07-20 17:36:44   \n",
       "38  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-20 21:49:00   \n",
       "39  {'classifier__C': 1.6102620275609394, 'classif...  2018-07-20 21:49:08   \n",
       "40  {'classifier__activation': 'logistic', 'classi...  2018-07-20 22:25:58   \n",
       "41  {'classifier__min_samples_leaf': 4, 'classifie...  2018-07-21 00:50:03   \n",
       "42  {'classifier__C': 13738.237958832638, 'classif...  2018-07-21 00:50:13   \n",
       "43  {'classifier__activation': 'relu', 'classifier...  2018-07-21 02:09:13   \n",
       "44  {'classifier__min_samples_leaf': 4, 'classifie...  2018-07-21 15:48:24   \n",
       "45  {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-21 15:48:36   \n",
       "46  {'classifier__activation': 'relu', 'classifier...  2018-07-21 18:11:39   \n",
       "47  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-22 04:42:08   \n",
       "48  {'classifier__C': 4.1753189365604015, 'classif...  2018-07-22 04:42:21   \n",
       "49  {'classifier__activation': 'relu', 'classifier...  2018-07-22 08:35:18   \n",
       "50  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-25 11:21:22   \n",
       "51  {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-25 11:21:31   \n",
       "52  {'classifier__activation': 'relu', 'classifier...  2018-07-25 11:25:49   \n",
       "53  {'classifier__learning_rate': 0.01487352107293...  2018-07-25 12:00:03   \n",
       "54  {'classifier__activation': 'relu', 'classifier...  2018-07-25 12:00:05   \n",
       "55                       {'classifier__priors': None}  2018-07-25 12:00:05   \n",
       "56  {'classifier__n_neighbors': 60, 'classifier__p...  2018-07-25 12:00:05   \n",
       "57  {'classifier__C': 1.6102620275609394, 'classif...  2018-07-25 12:00:05   \n",
       "58  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-25 12:00:05   \n",
       "59              {'classifier__C': 1.9952623149688795}  2018-07-25 12:00:06   \n",
       "60  {'classifier__C': 0.27825594022071259, 'classi...  2018-07-25 12:00:06   \n",
       "61  {'classifier__gamma': 0.031622776601683791, 'c...  2018-07-25 12:00:06   \n",
       "\n",
       "     variant  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "5        NaN  \n",
       "6        NaN  \n",
       "7        NaN  \n",
       "8        NaN  \n",
       "9        FSS  \n",
       "10       FSS  \n",
       "11       FSS  \n",
       "12       FSS  \n",
       "13       FSS  \n",
       "14       FSS  \n",
       "15       FSS  \n",
       "16       FSS  \n",
       "17       FSS  \n",
       "18        V3  \n",
       "19        V3  \n",
       "20        V3  \n",
       "21        V3  \n",
       "22        V3  \n",
       "23        V3  \n",
       "24        V3  \n",
       "25        V3  \n",
       "26        V3  \n",
       "27     FSSV3  \n",
       "28     FSSV3  \n",
       "29     FSSV3  \n",
       "..       ...  \n",
       "32     FSSV3  \n",
       "33     FSSV3  \n",
       "34     FSSV3  \n",
       "35       PCA  \n",
       "36       PCA  \n",
       "37     5FOLD  \n",
       "38     5FOLD  \n",
       "39     5FOLD  \n",
       "40     5FOLD  \n",
       "41    10FOLD  \n",
       "42    10FOLD  \n",
       "43    10FOLD  \n",
       "44    20FOLD  \n",
       "45    20FOLD  \n",
       "46    20FOLD  \n",
       "47    30FOLD  \n",
       "48    30FOLD  \n",
       "49    30FOLD  \n",
       "50  2FOLDMCC  \n",
       "51  2FOLDMCC  \n",
       "52  2FOLDMCC  \n",
       "53        V3  \n",
       "54        V3  \n",
       "55        V3  \n",
       "56        V3  \n",
       "57        V3  \n",
       "58        V3  \n",
       "59        V3  \n",
       "60        V3  \n",
       "61        V3  \n",
       "\n",
       "[62 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtbricker\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_cv_acc</th>\n",
       "      <th>holdout_acc</th>\n",
       "      <th>validation_acc</th>\n",
       "      <th>cv</th>\n",
       "      <th>best_params</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>variant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 8, 'classifier__p'...</td>\n",
       "      <td>2018-07-14 21:26:17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0}</td>\n",
       "      <td>2018-07-14 21:26:24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svc_rbf</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 0.0016681005372000592, 'clas...</td>\n",
       "      <td>2018-07-14 21:26:32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-14 21:27:09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.00280721620394...</td>\n",
       "      <td>2018-07-14 21:27:36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None}</td>\n",
       "      <td>2018-07-14 21:27:38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>log</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-14 21:27:46</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ann</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'tanh', 'classifier...</td>\n",
       "      <td>2018-07-14 21:32:23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.01, 'classifier__learn...</td>\n",
       "      <td>2018-07-14 21:32:32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 8, 'classifier__p'...</td>\n",
       "      <td>2018-07-14 23:06:53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0}</td>\n",
       "      <td>2018-07-14 23:07:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svc_rbf</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 0.27825594022071259, 'classi...</td>\n",
       "      <td>2018-07-14 23:07:08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-14 23:07:45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ada</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.10000000000000...</td>\n",
       "      <td>2018-07-14 23:08:11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None}</td>\n",
       "      <td>2018-07-14 23:08:13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>log</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-14 23:08:21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ann</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'tanh', 'classifier...</td>\n",
       "      <td>2018-07-14 23:13:18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.017782794100389229, 'c...</td>\n",
       "      <td>2018-07-14 23:13:27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 8, 'classifier__p'...</td>\n",
       "      <td>2018-07-14 23:47:24</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>knn</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 16, 'classifier__p...</td>\n",
       "      <td>2018-07-15 11:21:53</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'kbest__k': 10}</td>\n",
       "      <td>2018-07-15 11:24:20</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.00108263673387...</td>\n",
       "      <td>2018-07-15 11:34:38</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None, 'kbest__k': 15}</td>\n",
       "      <td>2018-07-15 11:34:45</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>log</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 10.826367338740546, 'classif...</td>\n",
       "      <td>2018-07-15 11:34:52</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 4, 'classifie...</td>\n",
       "      <td>2018-07-15 14:57:04</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ann</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>2018-07-15 15:32:27</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.017782794100389229, 'c...</td>\n",
       "      <td>2018-07-15 15:32:41</td>\n",
       "      <td>FSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.00280721620394...</td>\n",
       "      <td>2018-07-18 01:38:02</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ann</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'tanh', 'classifier...</td>\n",
       "      <td>2018-07-18 01:38:02</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None}</td>\n",
       "      <td>2018-07-18 01:38:02</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None, 'kbest__k': 15}</td>\n",
       "      <td>2018-07-18 01:52:35</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 8, 'classifier__p'...</td>\n",
       "      <td>2018-07-18 01:52:35</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>log</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 10.826367338740546, 'classif...</td>\n",
       "      <td>2018-07-18 01:52:35</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 4, 'classifie...</td>\n",
       "      <td>2018-07-18 01:52:35</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'kbest__k': 10}</td>\n",
       "      <td>2018-07-18 01:52:35</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.017782794100389229, 'c...</td>\n",
       "      <td>2018-07-18 01:52:35</td>\n",
       "      <td>FSSV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None, 'pca__n_component...</td>\n",
       "      <td>2018-07-18 02:52:20</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None, 'pca__n_component...</td>\n",
       "      <td>2018-07-18 02:55:52</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>log</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-20 17:36:53</td>\n",
       "      <td>5FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 4, 'classifie...</td>\n",
       "      <td>2018-07-20 22:27:06</td>\n",
       "      <td>5FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>log</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-20 22:27:15</td>\n",
       "      <td>5FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ann</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'classifier__activation': 'tanh', 'classifier...</td>\n",
       "      <td>2018-07-20 22:38:24</td>\n",
       "      <td>5FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-21 02:11:20</td>\n",
       "      <td>10FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>log</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-21 02:11:28</td>\n",
       "      <td>10FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ann</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'classifier__activation': 'identity', 'classi...</td>\n",
       "      <td>2018-07-21 02:34:53</td>\n",
       "      <td>10FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>20.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-21 18:15:46</td>\n",
       "      <td>20FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>log</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-21 18:15:55</td>\n",
       "      <td>20FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ann</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>20.0</td>\n",
       "      <td>{'classifier__activation': 'identity', 'classi...</td>\n",
       "      <td>2018-07-21 19:05:27</td>\n",
       "      <td>20FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 7, 'classifie...</td>\n",
       "      <td>2018-07-22 08:41:18</td>\n",
       "      <td>30FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>log</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-22 08:41:28</td>\n",
       "      <td>30FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ann</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{'classifier__activation': 'identity', 'classi...</td>\n",
       "      <td>2018-07-22 09:55:20</td>\n",
       "      <td>30FOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.00280721620394...</td>\n",
       "      <td>2018-07-25 12:00:06</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ann</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'tanh', 'classifier...</td>\n",
       "      <td>2018-07-25 12:00:07</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None}</td>\n",
       "      <td>2018-07-25 12:00:07</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 8, 'classifier__p'...</td>\n",
       "      <td>2018-07-25 12:00:07</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>log</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-25 12:00:07</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>rand_for</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-25 12:00:07</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>svc_lin</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0}</td>\n",
       "      <td>2018-07-25 12:00:07</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>svc_rbf</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 0.0016681005372000592, 'clas...</td>\n",
       "      <td>2018-07-25 12:00:07</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.01, 'classifier__learn...</td>\n",
       "      <td>2018-07-25 12:00:07</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  mean_cv_acc  holdout_acc  validation_acc    cv  \\\n",
       "0        knn     0.823529     0.818182        0.687500   2.0   \n",
       "1    svc_lin     0.976471     0.681818        0.812500   2.0   \n",
       "2    svc_rbf     0.823529     0.818182        0.750000   2.0   \n",
       "3   rand_for     1.000000     0.954545        0.750000   2.0   \n",
       "4        ada     0.823529     0.863636        0.812500   2.0   \n",
       "5        gnb     0.858824     0.818182        0.750000   2.0   \n",
       "6        log     0.952941     0.818182        0.812500   2.0   \n",
       "7        ann     0.941176     0.772727        0.750000   2.0   \n",
       "8    xgboost     1.000000     0.545455        0.687500   2.0   \n",
       "9        knn     0.823529     0.818182        0.812500   2.0   \n",
       "10   svc_lin     0.976471     0.681818        0.687500   2.0   \n",
       "11   svc_rbf     0.800000     0.818182        0.687500   2.0   \n",
       "12  rand_for     1.000000     0.909091        0.625000   2.0   \n",
       "13       ada     1.000000     0.772727        0.562500   2.0   \n",
       "14       gnb     0.858824     0.909091        0.625000   2.0   \n",
       "15       log     0.952941     0.818182        0.687500   2.0   \n",
       "16       ann     0.905882     0.772727        0.687500   2.0   \n",
       "17   xgboost     1.000000     0.727273        0.375000   2.0   \n",
       "18       knn     0.823529     0.863636        0.875000   2.0   \n",
       "19       knn     1.000000     0.772727        0.812500   2.0   \n",
       "20   svc_lin     0.858824     0.818182        0.750000   2.0   \n",
       "21       ada     0.741176     0.636364        0.750000   2.0   \n",
       "22       gnb     0.823529     0.863636        0.562500   2.0   \n",
       "23       log     0.847059     0.772727        0.625000   2.0   \n",
       "24  rand_for     0.952941     0.818182        0.875000   2.0   \n",
       "25       ann     0.870588     0.818182        0.812500   2.0   \n",
       "26   xgboost     1.000000     0.909091        0.750000   2.0   \n",
       "27       ada     0.823529     0.727273        0.700000   2.0   \n",
       "28       ann     0.941176     0.863636        0.800000   2.0   \n",
       "29       gnb     0.858824     0.863636        0.733333   2.0   \n",
       "..       ...          ...          ...             ...   ...   \n",
       "38       gnb     0.823529     0.772727        0.866667   2.0   \n",
       "39       knn     0.823529     0.772727        0.833333   2.0   \n",
       "40       log     0.847059     0.772727        0.900000   2.0   \n",
       "41  rand_for     0.952941     0.863636        0.833333   2.0   \n",
       "42   svc_lin     0.858824     0.727273        0.800000   2.0   \n",
       "43   xgboost     1.000000     0.727273        0.766667   2.0   \n",
       "44       gnb     0.788235     0.818182        0.750000   2.0   \n",
       "45       gnb     0.788235     0.818182        0.812500   2.0   \n",
       "46       log     0.952941     0.818182        0.812500   5.0   \n",
       "47  rand_for     0.976471     0.818182        0.687500   5.0   \n",
       "48       log     0.952941     0.772727        0.687500   5.0   \n",
       "49       ann     0.905882     0.863636        0.937500   5.0   \n",
       "50  rand_for     1.000000     0.818182        0.937500  10.0   \n",
       "51       log     0.952941     0.818182        0.937500  10.0   \n",
       "52       ann     0.905882     0.863636        1.000000  10.0   \n",
       "53  rand_for     0.988235     0.863636        0.812500  20.0   \n",
       "54       log     0.952941     0.772727        0.875000  20.0   \n",
       "55       ann     0.929412     0.909091        0.937500  20.0   \n",
       "56  rand_for     0.929412     0.863636        0.875000  30.0   \n",
       "57       log     0.941176     0.772727        0.687500  30.0   \n",
       "58       ann     0.929412     0.818182        0.812500  30.0   \n",
       "59       ada     0.823529     0.818182        0.600000   2.0   \n",
       "60       ann     0.941176     0.818182        0.700000   2.0   \n",
       "61       gnb     0.858824     0.863636        0.766667   2.0   \n",
       "62       knn     0.823529     0.818182        0.766667   2.0   \n",
       "63       log     0.952941     0.727273        0.733333   2.0   \n",
       "64  rand_for     1.000000     0.727273        0.900000   2.0   \n",
       "65   svc_lin     0.976471     0.772727        0.700000   2.0   \n",
       "66   svc_rbf     0.823529     0.772727        0.633333   2.0   \n",
       "67   xgboost     1.000000     0.636364        0.800000   2.0   \n",
       "\n",
       "                                          best_params        date_modified  \\\n",
       "0   {'classifier__n_neighbors': 8, 'classifier__p'...  2018-07-14 21:26:17   \n",
       "1                              {'classifier__C': 1.0}  2018-07-14 21:26:24   \n",
       "2   {'classifier__C': 0.0016681005372000592, 'clas...  2018-07-14 21:26:32   \n",
       "3   {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-14 21:27:09   \n",
       "4   {'classifier__learning_rate': 0.00280721620394...  2018-07-14 21:27:36   \n",
       "5                        {'classifier__priors': None}  2018-07-14 21:27:38   \n",
       "6   {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-14 21:27:46   \n",
       "7   {'classifier__activation': 'tanh', 'classifier...  2018-07-14 21:32:23   \n",
       "8   {'classifier__gamma': 0.01, 'classifier__learn...  2018-07-14 21:32:32   \n",
       "9   {'classifier__n_neighbors': 8, 'classifier__p'...  2018-07-14 23:06:53   \n",
       "10                             {'classifier__C': 1.0}  2018-07-14 23:07:00   \n",
       "11  {'classifier__C': 0.27825594022071259, 'classi...  2018-07-14 23:07:08   \n",
       "12  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-14 23:07:45   \n",
       "13  {'classifier__learning_rate': 0.10000000000000...  2018-07-14 23:08:11   \n",
       "14                       {'classifier__priors': None}  2018-07-14 23:08:13   \n",
       "15  {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-14 23:08:21   \n",
       "16  {'classifier__activation': 'tanh', 'classifier...  2018-07-14 23:13:18   \n",
       "17  {'classifier__gamma': 0.017782794100389229, 'c...  2018-07-14 23:13:27   \n",
       "18  {'classifier__n_neighbors': 8, 'classifier__p'...  2018-07-14 23:47:24   \n",
       "19  {'classifier__n_neighbors': 16, 'classifier__p...  2018-07-15 11:21:53   \n",
       "20             {'classifier__C': 1.0, 'kbest__k': 10}  2018-07-15 11:24:20   \n",
       "21  {'classifier__learning_rate': 0.00108263673387...  2018-07-15 11:34:38   \n",
       "22       {'classifier__priors': None, 'kbest__k': 15}  2018-07-15 11:34:45   \n",
       "23  {'classifier__C': 10.826367338740546, 'classif...  2018-07-15 11:34:52   \n",
       "24  {'classifier__min_samples_leaf': 4, 'classifie...  2018-07-15 14:57:04   \n",
       "25  {'classifier__activation': 'relu', 'classifier...  2018-07-15 15:32:27   \n",
       "26  {'classifier__gamma': 0.017782794100389229, 'c...  2018-07-15 15:32:41   \n",
       "27  {'classifier__learning_rate': 0.00280721620394...  2018-07-18 01:38:02   \n",
       "28  {'classifier__activation': 'tanh', 'classifier...  2018-07-18 01:38:02   \n",
       "29                       {'classifier__priors': None}  2018-07-18 01:38:02   \n",
       "..                                                ...                  ...   \n",
       "38       {'classifier__priors': None, 'kbest__k': 15}  2018-07-18 01:52:35   \n",
       "39  {'classifier__n_neighbors': 8, 'classifier__p'...  2018-07-18 01:52:35   \n",
       "40  {'classifier__C': 10.826367338740546, 'classif...  2018-07-18 01:52:35   \n",
       "41  {'classifier__min_samples_leaf': 4, 'classifie...  2018-07-18 01:52:35   \n",
       "42             {'classifier__C': 1.0, 'kbest__k': 10}  2018-07-18 01:52:35   \n",
       "43  {'classifier__gamma': 0.017782794100389229, 'c...  2018-07-18 01:52:35   \n",
       "44  {'classifier__priors': None, 'pca__n_component...  2018-07-18 02:52:20   \n",
       "45  {'classifier__priors': None, 'pca__n_component...  2018-07-18 02:55:52   \n",
       "46  {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-20 17:36:53   \n",
       "47  {'classifier__min_samples_leaf': 4, 'classifie...  2018-07-20 22:27:06   \n",
       "48  {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-20 22:27:15   \n",
       "49  {'classifier__activation': 'tanh', 'classifier...  2018-07-20 22:38:24   \n",
       "50  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-21 02:11:20   \n",
       "51  {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-21 02:11:28   \n",
       "52  {'classifier__activation': 'identity', 'classi...  2018-07-21 02:34:53   \n",
       "53  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-21 18:15:46   \n",
       "54  {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-21 18:15:55   \n",
       "55  {'classifier__activation': 'identity', 'classi...  2018-07-21 19:05:27   \n",
       "56  {'classifier__min_samples_leaf': 7, 'classifie...  2018-07-22 08:41:18   \n",
       "57  {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-22 08:41:28   \n",
       "58  {'classifier__activation': 'identity', 'classi...  2018-07-22 09:55:20   \n",
       "59  {'classifier__learning_rate': 0.00280721620394...  2018-07-25 12:00:06   \n",
       "60  {'classifier__activation': 'tanh', 'classifier...  2018-07-25 12:00:07   \n",
       "61                       {'classifier__priors': None}  2018-07-25 12:00:07   \n",
       "62  {'classifier__n_neighbors': 8, 'classifier__p'...  2018-07-25 12:00:07   \n",
       "63  {'classifier__C': 1.0, 'classifier__penalty': ...  2018-07-25 12:00:07   \n",
       "64  {'classifier__min_samples_leaf': 1, 'classifie...  2018-07-25 12:00:07   \n",
       "65                             {'classifier__C': 1.0}  2018-07-25 12:00:07   \n",
       "66  {'classifier__C': 0.0016681005372000592, 'clas...  2018-07-25 12:00:07   \n",
       "67  {'classifier__gamma': 0.01, 'classifier__learn...  2018-07-25 12:00:07   \n",
       "\n",
       "   variant  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  \n",
       "5      NaN  \n",
       "6      NaN  \n",
       "7      NaN  \n",
       "8      NaN  \n",
       "9      NaN  \n",
       "10     NaN  \n",
       "11     NaN  \n",
       "12     NaN  \n",
       "13     NaN  \n",
       "14     NaN  \n",
       "15     NaN  \n",
       "16     NaN  \n",
       "17     NaN  \n",
       "18     FSS  \n",
       "19     FSS  \n",
       "20     FSS  \n",
       "21     FSS  \n",
       "22     FSS  \n",
       "23     FSS  \n",
       "24     FSS  \n",
       "25     FSS  \n",
       "26     FSS  \n",
       "27      V3  \n",
       "28      V3  \n",
       "29      V3  \n",
       "..     ...  \n",
       "38   FSSV3  \n",
       "39   FSSV3  \n",
       "40   FSSV3  \n",
       "41   FSSV3  \n",
       "42   FSSV3  \n",
       "43   FSSV3  \n",
       "44     PCA  \n",
       "45     PCA  \n",
       "46   5FOLD  \n",
       "47   5FOLD  \n",
       "48   5FOLD  \n",
       "49   5FOLD  \n",
       "50  10FOLD  \n",
       "51  10FOLD  \n",
       "52  10FOLD  \n",
       "53  20FOLD  \n",
       "54  20FOLD  \n",
       "55  20FOLD  \n",
       "56  30FOLD  \n",
       "57  30FOLD  \n",
       "58  30FOLD  \n",
       "59      V3  \n",
       "60      V3  \n",
       "61      V3  \n",
       "62      V3  \n",
       "63      V3  \n",
       "64      V3  \n",
       "65      V3  \n",
       "66      V3  \n",
       "67      V3  \n",
       "\n",
       "[68 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This code creates a model using the best parameters and creates a new table row for each model using the new 3.0 Validation Data\n",
    "\n",
    "groupings = [\n",
    "    {'name': 'cvp', 'grouping':{0:0, 1:1, 2:1, 3:1}, 'description':'Control vs. All Parkinsons', 'data_file':'gridCV_cvp.csv'},\n",
    "    {'name': 'iva', 'grouping':{1:1, 2:2, 3:2},'description':'Idiopathic vs. Atypical Parkinsons', 'data_file':'gridCV_iva.csv'},\n",
    "    {'name': 'mvp', 'grouping':{2:2, 3:3},'description':'MSA vs. PSP', 'data_file':'gridCV_mvp.csv'}\n",
    "]\n",
    "\n",
    "for grouping in groupings:\n",
    "    with mu.HiddenPrints():\n",
    "        X, y , Xh, yh, Xv, yv = mu.get_training_holdout_validation_data(grouping['grouping'], use_v3=True)\n",
    "    \n",
    "    df = getData(data_file=grouping['data_file'])\n",
    "    \n",
    "    for index, row in df.loc[df.variant.isnull()].groupby('model').first().iterrows():\n",
    "#         print(\"%10s %10f %10f\"%(row.name, row.holdout_acc, row.validation_acc))\n",
    "        mod = getOptimizedModel(row.name,eval(row.best_params))\n",
    "        mod.fit(X,y)\n",
    "        row.holdout_acc = mod.score(Xh,yh)\n",
    "        row.validation_acc = mod.score(Xv,yv)\n",
    "        row.date_modified = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        row.variant = 'V3'\n",
    "        row['model'] = row.name\n",
    "#         print(\"%10s %10f %10f\"%(row.name, row.holdout_acc, row.validation_acc))\n",
    "        df = df.append(row, ignore_index=True)\n",
    "\n",
    "#     saveData(df, grouping['data_file'])\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.911764705882\n",
      "0.958333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_cv_acc</th>\n",
       "      <th>holdout_acc</th>\n",
       "      <th>validation_acc</th>\n",
       "      <th>cv</th>\n",
       "      <th>best_params</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>variant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.944631</td>\n",
       "      <td>0.906863</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.01487352107293...</td>\n",
       "      <td>2018-07-14 19:26:33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ann</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'tanh', 'classifier...</td>\n",
       "      <td>2018-07-14 19:41:32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gnb</th>\n",
       "      <td>0.845638</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None}</td>\n",
       "      <td>2018-07-14 19:26:35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 60, 'classifier__p...</td>\n",
       "      <td>2018-07-14 19:24:35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log</th>\n",
       "      <td>0.963087</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-14 19:26:44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rand_for</th>\n",
       "      <td>0.971477</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-14 19:25:49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_lin</th>\n",
       "      <td>0.969799</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.9952623149688795}</td>\n",
       "      <td>2018-07-14 19:24:43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_rbf</th>\n",
       "      <td>0.963087</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1291549.6650148828, 'classif...</td>\n",
       "      <td>2018-07-14 19:24:55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.017782794100389229, 'c...</td>\n",
       "      <td>2018-07-14 19:41:47</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean_cv_acc  holdout_acc  validation_acc   cv  \\\n",
       "model                                                     \n",
       "ada          0.944631     0.906863        0.988636  2.0   \n",
       "ann          1.000000     0.931373        0.988636  2.0   \n",
       "gnb          0.845638     0.794118        0.943182  2.0   \n",
       "knn          1.000000     0.750000        0.829545  2.0   \n",
       "log          0.963087     0.911765        0.988636  2.0   \n",
       "rand_for     0.971477     0.911765        0.988636  2.0   \n",
       "svc_lin      0.969799     0.911765        0.977273  2.0   \n",
       "svc_rbf      0.963087     0.897059        0.977273  2.0   \n",
       "xgboost      1.000000     0.926471        0.988636  2.0   \n",
       "\n",
       "                                                best_params  \\\n",
       "model                                                         \n",
       "ada       {'classifier__learning_rate': 0.01487352107293...   \n",
       "ann       {'classifier__activation': 'tanh', 'classifier...   \n",
       "gnb                            {'classifier__priors': None}   \n",
       "knn       {'classifier__n_neighbors': 60, 'classifier__p...   \n",
       "log       {'classifier__C': 1.0, 'classifier__penalty': ...   \n",
       "rand_for  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "svc_lin               {'classifier__C': 1.9952623149688795}   \n",
       "svc_rbf   {'classifier__C': 1291549.6650148828, 'classif...   \n",
       "xgboost   {'classifier__gamma': 0.017782794100389229, 'c...   \n",
       "\n",
       "                date_modified  variant  \n",
       "model                                   \n",
       "ada       2018-07-14 19:26:33      NaN  \n",
       "ann       2018-07-14 19:41:32      NaN  \n",
       "gnb       2018-07-14 19:26:35      NaN  \n",
       "knn       2018-07-14 19:24:35      NaN  \n",
       "log       2018-07-14 19:26:44      NaN  \n",
       "rand_for  2018-07-14 19:25:49      NaN  \n",
       "svc_lin   2018-07-14 19:24:43      NaN  \n",
       "svc_rbf   2018-07-14 19:24:55      NaN  \n",
       "xgboost   2018-07-14 19:41:47      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtbricker\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79375\n",
      "0.837837837838\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_cv_acc</th>\n",
       "      <th>holdout_acc</th>\n",
       "      <th>validation_acc</th>\n",
       "      <th>cv</th>\n",
       "      <th>best_params</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>variant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.918317</td>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.01487352107293...</td>\n",
       "      <td>2018-07-14 19:44:01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ann</th>\n",
       "      <td>0.950495</td>\n",
       "      <td>0.86875</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "      <td>2018-07-14 19:59:19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gnb</th>\n",
       "      <td>0.878713</td>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None}</td>\n",
       "      <td>2018-07-14 19:44:03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.898515</td>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 60, 'classifier__p...</td>\n",
       "      <td>2018-07-14 19:42:10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log</th>\n",
       "      <td>0.896040</td>\n",
       "      <td>0.83750</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.6102620275609394, 'classif...</td>\n",
       "      <td>2018-07-14 19:44:12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rand_for</th>\n",
       "      <td>0.995050</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-14 19:43:21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_lin</th>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.9952623149688795}</td>\n",
       "      <td>2018-07-14 19:42:20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_rbf</th>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 0.27825594022071259, 'classi...</td>\n",
       "      <td>2018-07-14 19:42:30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.031622776601683791, 'c...</td>\n",
       "      <td>2018-07-14 19:59:33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean_cv_acc  holdout_acc  validation_acc   cv  \\\n",
       "model                                                     \n",
       "ada          0.918317      0.80625        0.968750  2.0   \n",
       "ann          0.950495      0.86875        0.859375  2.0   \n",
       "gnb          0.878713      0.80625        0.937500  2.0   \n",
       "knn          0.898515      0.80625        0.859375  2.0   \n",
       "log          0.896040      0.83750        0.859375  2.0   \n",
       "rand_for     0.995050      0.80000        0.875000  2.0   \n",
       "svc_lin      0.891089      0.79375        0.828125  2.0   \n",
       "svc_rbf      0.900990      0.78125        0.921875  2.0   \n",
       "xgboost      1.000000      0.78125        0.937500  2.0   \n",
       "\n",
       "                                                best_params  \\\n",
       "model                                                         \n",
       "ada       {'classifier__learning_rate': 0.01487352107293...   \n",
       "ann       {'classifier__activation': 'relu', 'classifier...   \n",
       "gnb                            {'classifier__priors': None}   \n",
       "knn       {'classifier__n_neighbors': 60, 'classifier__p...   \n",
       "log       {'classifier__C': 1.6102620275609394, 'classif...   \n",
       "rand_for  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "svc_lin               {'classifier__C': 1.9952623149688795}   \n",
       "svc_rbf   {'classifier__C': 0.27825594022071259, 'classi...   \n",
       "xgboost   {'classifier__gamma': 0.031622776601683791, 'c...   \n",
       "\n",
       "                date_modified  variant  \n",
       "model                                   \n",
       "ada       2018-07-14 19:44:01      NaN  \n",
       "ann       2018-07-14 19:59:19      NaN  \n",
       "gnb       2018-07-14 19:44:03      NaN  \n",
       "knn       2018-07-14 19:42:10      NaN  \n",
       "log       2018-07-14 19:44:12      NaN  \n",
       "rand_for  2018-07-14 19:43:21      NaN  \n",
       "svc_lin   2018-07-14 19:42:20      NaN  \n",
       "svc_rbf   2018-07-14 19:42:30      NaN  \n",
       "xgboost   2018-07-14 19:59:33      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtbricker\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818181818182\n",
      "0.733333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_cv_acc</th>\n",
       "      <th>holdout_acc</th>\n",
       "      <th>validation_acc</th>\n",
       "      <th>cv</th>\n",
       "      <th>best_params</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>variant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__learning_rate': 0.00280721620394...</td>\n",
       "      <td>2018-07-14 21:27:36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ann</th>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__activation': 'tanh', 'classifier...</td>\n",
       "      <td>2018-07-14 21:32:23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gnb</th>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__priors': None}</td>\n",
       "      <td>2018-07-14 21:27:38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__n_neighbors': 8, 'classifier__p'...</td>\n",
       "      <td>2018-07-14 21:26:17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log</th>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0, 'classifier__penalty': ...</td>\n",
       "      <td>2018-07-14 21:27:46</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rand_for</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>2018-07-14 21:27:09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_lin</th>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 1.0}</td>\n",
       "      <td>2018-07-14 21:26:24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_rbf</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__C': 0.0016681005372000592, 'clas...</td>\n",
       "      <td>2018-07-14 21:26:32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'classifier__gamma': 0.01, 'classifier__learn...</td>\n",
       "      <td>2018-07-14 21:32:32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean_cv_acc  holdout_acc  validation_acc   cv  \\\n",
       "model                                                     \n",
       "ada          0.823529     0.863636          0.8125  2.0   \n",
       "ann          0.941176     0.772727          0.7500  2.0   \n",
       "gnb          0.858824     0.818182          0.7500  2.0   \n",
       "knn          0.823529     0.818182          0.6875  2.0   \n",
       "log          0.952941     0.818182          0.8125  2.0   \n",
       "rand_for     1.000000     0.954545          0.7500  2.0   \n",
       "svc_lin      0.976471     0.681818          0.8125  2.0   \n",
       "svc_rbf      0.823529     0.818182          0.7500  2.0   \n",
       "xgboost      1.000000     0.545455          0.6875  2.0   \n",
       "\n",
       "                                                best_params  \\\n",
       "model                                                         \n",
       "ada       {'classifier__learning_rate': 0.00280721620394...   \n",
       "ann       {'classifier__activation': 'tanh', 'classifier...   \n",
       "gnb                            {'classifier__priors': None}   \n",
       "knn       {'classifier__n_neighbors': 8, 'classifier__p'...   \n",
       "log       {'classifier__C': 1.0, 'classifier__penalty': ...   \n",
       "rand_for  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "svc_lin                              {'classifier__C': 1.0}   \n",
       "svc_rbf   {'classifier__C': 0.0016681005372000592, 'clas...   \n",
       "xgboost   {'classifier__gamma': 0.01, 'classifier__learn...   \n",
       "\n",
       "                date_modified  variant  \n",
       "model                                   \n",
       "ada       2018-07-14 21:27:36      NaN  \n",
       "ann       2018-07-14 21:32:23      NaN  \n",
       "gnb       2018-07-14 21:27:38      NaN  \n",
       "knn       2018-07-14 21:26:17      NaN  \n",
       "log       2018-07-14 21:27:46      NaN  \n",
       "rand_for  2018-07-14 21:27:09      NaN  \n",
       "svc_lin   2018-07-14 21:26:24      NaN  \n",
       "svc_rbf   2018-07-14 21:26:32      NaN  \n",
       "xgboost   2018-07-14 21:32:32      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This code creates an ensemble voting model using all 8 base models with optimized parameters\n",
    "from scipy import stats\n",
    "\n",
    "groupings = [\n",
    "    {'name': 'cvp', 'grouping':{0:0, 1:1, 2:1, 3:1}, 'description':'Control vs. All Parkinsons', 'data_file':'gridCV_cvp.csv'},\n",
    "    {'name': 'iva', 'grouping':{1:1, 2:2, 3:2},'description':'Idiopathic vs. Atypical Parkinsons', 'data_file':'gridCV_iva.csv'},\n",
    "    {'name': 'mvp', 'grouping':{2:2, 3:3},'description':'MSA vs. PSP', 'data_file':'gridCV_mvp.csv'}\n",
    "]\n",
    "\n",
    "for grouping in groupings[:]:\n",
    "    with mu.HiddenPrints():\n",
    "        X, y , Xh, yh, Xv, yv = mu.get_training_holdout_validation_data(grouping['grouping'], use_v3=True)\n",
    "    \n",
    "    df = getData(data_file=grouping['data_file'])\n",
    "    \n",
    "    models = []\n",
    "    for index, row in df.loc[df.variant.isnull()].groupby('model').first().iterrows():\n",
    "        mod = getOptimizedModel(row.name,eval(row.best_params))\n",
    "        mod.fit(X,y)\n",
    "        models.append(mod)\n",
    "        \n",
    "    # determine holdout accuracy\n",
    "    acc = []\n",
    "    for i in range(len(Xh)):\n",
    "        preds =[]\n",
    "        for m in models:\n",
    "            preds.append(m.predict(Xh[i].reshape(1, -1))[0])\n",
    "        pred = stats.mode(preds).mode[0]\n",
    "        acc.append(1 if pred == yh[i] else 0)\n",
    "    print(np.mean(acc))\n",
    "    \n",
    "    # determine validation accuracy\n",
    "    acc = []\n",
    "    for i in range(len(Xv)):\n",
    "        preds =[]\n",
    "        for m in models:\n",
    "            preds.append(m.predict(Xv[i].reshape(1, -1))[0])\n",
    "        pred = stats.mode(preds).mode[0]\n",
    "        acc.append(1 if pred == yv[i] else 0)\n",
    "    print(np.mean(acc))\n",
    "\n",
    "    display(df.loc[df.variant.isnull()].groupby('model').first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
