{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Modeling Benchmarks\n",
    "In this notebook I will benchmark various learning models using the same data without preprocessing, feature selection, and hyperparameter tuning to get a general idea for which models are performant on the multiclass classifier problem. Resampling will be used in both training and validation to ensure that minority classes get appropriate representation.\n",
    "\n",
    "8 models that we'll consider:\n",
    "* Logistic Regression\n",
    "* SVC with Linear Kernel\n",
    "* SVC with RBF Kernel\n",
    "* k-Nearest Neighbors\n",
    "* Decision Trees\n",
    "* Artificial Neural Networks\n",
    "* Naive Bayes\n",
    "* AdaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "\n",
    "import ml_utils as mu\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with mu.HiddenPrints():\n",
    "    data = mu.get_training_data()\n",
    "    X, y = mu.resample_to_equal_class_sizes(*mu.split_x_and_y(data))\n",
    "\n",
    "    valid_data = mu.get_validation_data(data.columns, use_mean_adjusted_data=True)\n",
    "    X_valid, y_valid = mu.resample_to_equal_class_sizes(*mu.split_x_and_y(valid_data))\n",
    "\n",
    "\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size = 0.2, random_state = 43, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "----------------------------------\n",
      "Cross-Validation Mean Accuracy: 0.818948\n",
      "----------------------------------\n",
      "Holdout Data Score: 0.853125\n",
      "\n",
      "[[76  1  2  1]\n",
      " [ 3 42 16 19]\n",
      " [ 0  1 79  0]\n",
      " [ 0  4  0 76]]\n",
      "\n",
      "----------------------------------\n",
      "Validation Data Score: 0.710938\n",
      "\n",
      "[[32  0  0  0]\n",
      " [ 0 15  9  8]\n",
      " [ 0  0 22 10]\n",
      " [ 0  1  9 22]]\n",
      "\n",
      "=======================================================================\n",
      "SVC(C=0.025, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "----------------------------------\n",
      "Cross-Validation Mean Accuracy: 0.664608\n",
      "----------------------------------\n",
      "Holdout Data Score: 0.687500\n",
      "\n",
      "[[76  0  2  2]\n",
      " [ 5 42 15 18]\n",
      " [ 0 11 55 14]\n",
      " [ 0  7 26 47]]\n",
      "\n",
      "----------------------------------\n",
      "Validation Data Score: 0.812500\n",
      "\n",
      "[[32  0  0  0]\n",
      " [ 1 17  7  7]\n",
      " [ 0  0 32  0]\n",
      " [ 0  0  9 23]]\n",
      "\n",
      "=======================================================================\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "----------------------------------\n",
      "Cross-Validation Mean Accuracy: 0.921577\n",
      "----------------------------------\n",
      "Holdout Data Score: 0.959375\n",
      "\n",
      "[[70 10  0  0]\n",
      " [ 0 78  2  0]\n",
      " [ 0  1 79  0]\n",
      " [ 0  0  0 80]]\n",
      "\n",
      "----------------------------------\n",
      "Validation Data Score: 0.328125\n",
      "\n",
      "[[ 5 27  0  0]\n",
      " [ 0 31  0  1]\n",
      " [ 0 32  0  0]\n",
      " [ 0 26  0  6]]\n",
      "\n",
      "=======================================================================\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "----------------------------------\n",
      "Cross-Validation Mean Accuracy: 0.906585\n",
      "----------------------------------\n",
      "Holdout Data Score: 0.896875\n",
      "\n",
      "[[76  3  0  1]\n",
      " [ 3 70  2  5]\n",
      " [ 0 12 63  5]\n",
      " [ 0  2  0 78]]\n",
      "\n",
      "----------------------------------\n",
      "Validation Data Score: 0.773438\n",
      "\n",
      "[[32  0  0  0]\n",
      " [ 1 30  1  0]\n",
      " [ 0  5 17 10]\n",
      " [ 0 12  0 20]]\n",
      "\n",
      "=======================================================================\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "----------------------------------\n",
      "Cross-Validation Mean Accuracy: 0.495176\n",
      "----------------------------------\n",
      "Holdout Data Score: 0.578125\n",
      "\n",
      "[[34  0  0 46]\n",
      " [ 2 57  5 16]\n",
      " [ 0 23 36 21]\n",
      " [ 0 16  6 58]]\n",
      "\n",
      "----------------------------------\n",
      "Validation Data Score: 0.468750\n",
      "\n",
      "[[10  0  0 22]\n",
      " [ 1 25  3  3]\n",
      " [ 0 16 16  0]\n",
      " [ 0  7 16  9]]\n",
      "\n",
      "=======================================================================\n",
      "GaussianNB(priors=None)\n",
      "----------------------------------\n",
      "Cross-Validation Mean Accuracy: 0.734313\n",
      "----------------------------------\n",
      "Holdout Data Score: 0.706250\n",
      "\n",
      "[[68  9  0  3]\n",
      " [11 60  2  7]\n",
      " [ 0 24 45 11]\n",
      " [ 1 20  6 53]]\n",
      "\n",
      "----------------------------------\n",
      "Validation Data Score: 0.726562\n",
      "\n",
      "[[25  7  0  0]\n",
      " [ 1 31  0  0]\n",
      " [ 0  5 17 10]\n",
      " [ 0 12  0 20]]\n",
      "\n",
      "=======================================================================\n",
      "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "----------------------------------\n",
      "Cross-Validation Mean Accuracy: 0.849467\n",
      "----------------------------------\n",
      "Holdout Data Score: 0.843750\n",
      "\n",
      "[[75  2  0  3]\n",
      " [ 6 59 10  5]\n",
      " [ 0  9 64  7]\n",
      " [ 0  5  3 72]]\n",
      "\n",
      "----------------------------------\n",
      "Validation Data Score: 0.695312\n",
      "\n",
      "[[25  0  0  7]\n",
      " [ 2 17 10  3]\n",
      " [ 0 10 22  0]\n",
      " [ 0  7  0 25]]\n",
      "\n",
      "=======================================================================\n",
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=[25, 25, 25], learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "----------------------------------\n",
      "Cross-Validation Mean Accuracy: 0.608891\n",
      "----------------------------------\n",
      "Holdout Data Score: 0.615625\n",
      "\n",
      "[[77  1  2  0]\n",
      " [ 4 48 26  2]\n",
      " [ 0 11 69  0]\n",
      " [ 2 27 48  3]]\n",
      "\n",
      "----------------------------------\n",
      "Validation Data Score: 0.617188\n",
      "\n",
      "[[32  0  0  0]\n",
      " [ 1 15 16  0]\n",
      " [ 0  0 32  0]\n",
      " [ 0  8 24  0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),\n",
    "    SVC(kernel='linear', C=0.025),\n",
    "    SVC(kernel='rbf', gamma=2, C=1),\n",
    "    RandomForestClassifier(max_depth=5),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(C=1e5),\n",
    "    MLPClassifier(hidden_layer_sizes=[25,25,25], alpha=1)\n",
    "]\n",
    "for model in classifiers:\n",
    "    print(\"=======================================================================\")\n",
    "    print(model)\n",
    "    print('----------------------------------')\n",
    "    print(\"Cross-Validation Mean Accuracy: %f\" %cross_val_score(model, X_train, y_train, cv=StratifiedKFold(5)).mean())\n",
    "    print('----------------------------------')\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_holdout)\n",
    "    print(\"Holdout Data Score: %f\" %clf.score(X_holdout, y_holdout))\n",
    "    print()\n",
    "    print(confusion_matrix(y_holdout, y_pred))\n",
    "    print()\n",
    "    print('----------------------------------')\n",
    "    y_valid_pred = clf.predict(X_valid)\n",
    "    print(\"Validation Data Score: %f\" %clf.score(X_valid, y_valid))\n",
    "    print()\n",
    "    print(confusion_matrix(y_valid, y_valid_pred))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
