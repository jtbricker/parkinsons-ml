{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def resample_to_equal_class_sizes(X,y):\n",
    "    df = pd.DataFrame(X)\n",
    "    df['group'] = [int(i) for i in y]\n",
    "    groups = []\n",
    "    for v in set(df['group']):\n",
    "        groups.append(df[df['group'] == v])\n",
    "           \n",
    "    max_length = max([len(group) for group in groups])\n",
    "    print(\"Maximum class size is %s\" %max_length)\n",
    "    \n",
    "    final_groups = []\n",
    "    for group in groups:\n",
    "        if len(group) < max_length:\n",
    "            print(\"Class %s size is %s. Resampling with replacement to %s\" %(max(group['group']),len(group), max_length))\n",
    "            final_groups.append(resample(group, replace=True, n_samples=max_length))\n",
    "        else:\n",
    "            print(\"Class %s size has max class size (%s).\" %(max(group['group']), max_length))\n",
    "            final_groups.append(group)\n",
    "    df = pd.concat(final_groups)\n",
    "    return df.drop('group', axis=1).values, df['group'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "import pandas as pd\n",
    "\n",
    "raw_data = pd.read_excel('data/training_data.xlsx')\n",
    "\n",
    "# remove unneeded subject ID column\n",
    "data = raw_data.drop('Subject', axis=1)\n",
    "\n",
    "# split x and y data\n",
    "y = data['GroupID']\n",
    "X = data.drop('GroupID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "import pandas as pd\n",
    "\n",
    "raw_validation_data = pd.read_excel('data/Validation.xlsx')\n",
    "\n",
    "# remove unneeded subject ID column\n",
    "validation_data = raw_validation_data[data.columns]\n",
    "\n",
    "# split x and y data\n",
    "y_valid = validation_data['GroupID']\n",
    "X_valid = validation_data.drop('GroupID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Validation Data 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "import pandas as pd\n",
    "\n",
    "raw_validation_data2 = pd.read_excel('data/Validation_2.0.xlsx')\n",
    "\n",
    "# remove unneeded subject ID column\n",
    "validation_data2 = raw_validation_data2[data.columns]\n",
    "\n",
    "# split x and y data\n",
    "y_valid2 = validation_data2['GroupID']\n",
    "X_valid2 = validation_data2.drop('GroupID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize all the data to training set and resample the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum class size is 399\n",
      "Class 0 size is 240. Resampling with replacement to 399\n",
      "Class 1 size has max class size (399).\n",
      "Class 2 size is 52. Resampling with replacement to 399\n",
      "Class 3 size is 55. Resampling with replacement to 399\n"
     ]
    }
   ],
   "source": [
    "# standardize the data by removing the mean (making it 0) and scaling to unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scale = StandardScaler().fit(X)\n",
    "\n",
    "X_std = std_scale.transform(X)\n",
    "X_valid_std = std_scale.transform(X_valid)\n",
    "X_valid_std2 = std_scale.transform(X_valid2)\n",
    "\n",
    "X_std_res, y_res = resample_to_equal_class_sizes(X_std, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=100, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-1, hidden_layer_sizes=(100), random_state=1)\n",
    "\n",
    "clf.fit(X_std_res,y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data 1 Score: 0.84\n",
      "Validation Data 2 Score: 0.86\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Data 1 Score:\", clf.score(X_valid_std, y_valid))\n",
    "print(\"Validation Data 2 Score:\", clf.score(X_valid_std2, y_valid2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     1\n",
       "7     1\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "16    1\n",
       "17    1\n",
       "18    1\n",
       "19    1\n",
       "20    1\n",
       "21    1\n",
       "22    1\n",
       "23    1\n",
       "24    1\n",
       "25    1\n",
       "26    1\n",
       "27    1\n",
       "28    1\n",
       "29    1\n",
       "30    1\n",
       "31    1\n",
       "32    1\n",
       "33    1\n",
       "34    1\n",
       "35    1\n",
       "36    1\n",
       "37    1\n",
       "38    2\n",
       "39    2\n",
       "40    2\n",
       "41    2\n",
       "42    3\n",
       "43    3\n",
       "44    3\n",
       "45    3\n",
       "46    3\n",
       "47    3\n",
       "48    3\n",
       "49    3\n",
       "Name: GroupID, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_valid2)\n",
    "y_valid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
