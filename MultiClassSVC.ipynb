{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### Set Random Number Seed\n",
    "np.random.seed(112)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = pd.read_excel(filename)\n",
    "    print(\"Loaded data with shape: \", data.shape)\n",
    "    \n",
    "    # Drop the subject column since its not used and contains non-numeric data\n",
    "    return data.drop('Subject', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(data, columns=None, include_control=True, combine_p_groups=False):\n",
    "    df = data.copy()\n",
    "    \n",
    "    if not include_control:\n",
    "        df = df[df.GroupID!=0]\n",
    "        \n",
    "    if columns:\n",
    "        df = df[columns]\n",
    "\n",
    "    if combine_p_groups:\n",
    "        df.loc[df['GroupID'] != 0, 'GroupID'] = 1 \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(df):\n",
    "    df_control =df[df.GroupID==0]  #246\n",
    "    df_park = df[df.GroupID==1] #399\n",
    "    df_msa = df[df.GroupID==2]  #52\n",
    "    df_psp = df[df.GroupID==3]  #55\n",
    "\n",
    "    max_length = max([len(df_park), len(df_msa), len(df_psp), len(df_control)])\n",
    "\n",
    "    if len(df_control) > 0:\n",
    "        df_control = resample(df_control, replace=True, n_samples=max_length, random_state=3)\n",
    "    if len(df_msa) > 0:\n",
    "        df_msa = resample(df_msa, replace=True, n_samples=max_length, random_state=1)\n",
    "    if len(df_psp) > 0:\n",
    "        df_psp = resample(df_psp, replace=True, n_samples=max_length, random_state=2)\n",
    "\n",
    "    return pd.concat([df_control, df_park, df_msa, df_psp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_x_y_data(df, ylabel=\"GroupID\"):\n",
    "    x_cols = [col for col in df.columns if col != ylabel]\n",
    "    Xd = pd.DataFrame(df, columns= x_cols)\n",
    "    Yd = df[ylabel]\n",
    "    return Xd, Yd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(X_train, X_test):\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    return X_train_std, X_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_grid_search(X_train, X_test, y_train, y_test, cv=5):\n",
    "\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1,1e-1,1e-2,1e-3, 1e-4],\n",
    "                         'C': [1, 10, 100, 1000]},\n",
    "                        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "    print(\"# Tuning hyper-parameters for f1\")\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(svm.SVC(), tuned_parameters, cv=cv,\n",
    "                       scoring='f1_macro',\n",
    "                       n_jobs = -1 )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Groups, 7 Regions and UPDRS, Resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with shape:  (746, 39)\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.719 (+/-0.075) for {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.575 (+/-0.064) for {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.537 (+/-0.044) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.508 (+/-0.047) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.512 (+/-0.052) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.903 (+/-0.053) for {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.738 (+/-0.063) for {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.569 (+/-0.054) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.509 (+/-0.051) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.512 (+/-0.044) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.934 (+/-0.036) for {'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.874 (+/-0.038) for {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.768 (+/-0.080) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.637 (+/-0.057) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.511 (+/-0.052) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.947 (+/-0.043) for {'C': 1000, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.920 (+/-0.055) for {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.825 (+/-0.070) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.771 (+/-0.066) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.658 (+/-0.080) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.749 (+/-0.080) for {'C': 1, 'kernel': 'linear'}\n",
      "0.790 (+/-0.072) for {'C': 10, 'kernel': 'linear'}\n",
      "0.796 (+/-0.083) for {'C': 100, 'kernel': 'linear'}\n",
      "0.788 (+/-0.072) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93        80\n",
      "          1       0.97      0.78      0.87        78\n",
      "          2       0.95      1.00      0.97        92\n",
      "          3       0.96      1.00      0.98        70\n",
      "\n",
      "avg / total       0.94      0.94      0.94       320\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the excel file\n",
    "data = load_data(\"real_data2.xlsx\")\n",
    "\n",
    "# Only grab the columns of interest.  TODO: Replace with list derived from feature selection\n",
    "columns_of_interest = [\"GroupID\",\"SCP_FW\",\"MCP_FW\",\"Putamen_FA\",\"Caudate_FA\",\"STN_FW\", \"RN_FW\", \"Thalamus_FA\", \"UPDRS\"]\n",
    "filtered_data = filter_data(data, columns=columns_of_interest)\n",
    "\n",
    "# Resample the data so that there are even numbers of each label\n",
    "resampled_data = resample_data(filtered_data)\n",
    "\n",
    "# Split predictor and response data\n",
    "X, y = split_x_y_data(resampled_data)\n",
    "\n",
    "# Shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "\n",
    "# standardize the data\n",
    "X_train_std, X_test_std = standardize_data(X_train, X_test)\n",
    "\n",
    "# Perform a grid search to find best SVC model\n",
    "svm_grid_search(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Groups, All Data, Resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with shape:  (746, 39)\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.719 (+/-0.075) for {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.575 (+/-0.064) for {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.537 (+/-0.044) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.508 (+/-0.047) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.512 (+/-0.052) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.903 (+/-0.053) for {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.738 (+/-0.063) for {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.569 (+/-0.054) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.509 (+/-0.051) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.512 (+/-0.044) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.934 (+/-0.036) for {'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.874 (+/-0.038) for {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.768 (+/-0.080) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.637 (+/-0.057) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.511 (+/-0.052) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.947 (+/-0.043) for {'C': 1000, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.920 (+/-0.055) for {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.825 (+/-0.070) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.771 (+/-0.066) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.658 (+/-0.080) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.749 (+/-0.080) for {'C': 1, 'kernel': 'linear'}\n",
      "0.790 (+/-0.072) for {'C': 10, 'kernel': 'linear'}\n",
      "0.796 (+/-0.083) for {'C': 100, 'kernel': 'linear'}\n",
      "0.788 (+/-0.072) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93        80\n",
      "          1       0.97      0.78      0.87        78\n",
      "          2       0.95      1.00      0.97        92\n",
      "          3       0.96      1.00      0.98        70\n",
      "\n",
      "avg / total       0.94      0.94      0.94       320\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the excel file\n",
    "data = load_data(\"real_data2.xlsx\")\n",
    "\n",
    "# Resample the data so that there are even numbers of each label\n",
    "resampled_data = resample_data(filtered_data)\n",
    "\n",
    "# Split predictor and response data\n",
    "X, y = split_x_y_data(resampled_data)\n",
    "\n",
    "# Shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "\n",
    "# standardize the data\n",
    "X_train_std, X_test_std = standardize_data(X_train, X_test)\n",
    "\n",
    "# Perform a grid search to find best SVC model\n",
    "svm_grid_search(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control vs. All Parkinsons, All Data, Resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with shape:  (746, 39)\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.960 (+/-0.068) for {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.959 (+/-0.062) for {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.949 (+/-0.042) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.948 (+/-0.040) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.948 (+/-0.036) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.959 (+/-0.065) for {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.958 (+/-0.051) for {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.947 (+/-0.052) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.949 (+/-0.050) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.947 (+/-0.031) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.959 (+/-0.065) for {'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.955 (+/-0.046) for {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.946 (+/-0.056) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.949 (+/-0.050) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.949 (+/-0.057) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.959 (+/-0.065) for {'C': 1000, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.955 (+/-0.046) for {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.949 (+/-0.039) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.951 (+/-0.054) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.947 (+/-0.052) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.954 (+/-0.044) for {'C': 1, 'kernel': 'linear'}\n",
      "0.960 (+/-0.049) for {'C': 10, 'kernel': 'linear'}\n",
      "0.960 (+/-0.036) for {'C': 100, 'kernel': 'linear'}\n",
      "0.947 (+/-0.048) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95        97\n",
      "          1       0.95      0.95      0.95       106\n",
      "\n",
      "avg / total       0.95      0.95      0.95       203\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the excel file\n",
    "data = load_data(\"real_data2.xlsx\")\n",
    "\n",
    "# Combine Parkinson's Groups\n",
    "filtered_data = filter_data(data, combine_p_groups=True)\n",
    "\n",
    "# Resample the data so that there are even numbers of each label\n",
    "resampled_data = resample_data(filtered_data)\n",
    "\n",
    "# Split predictor and response data\n",
    "X, y = split_x_y_data(resampled_data)\n",
    "\n",
    "# Shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "\n",
    "# standardize the data\n",
    "X_train_std, X_test_std = standardize_data(X_train, X_test)\n",
    "\n",
    "# Perform a grid search to find best SVC model\n",
    "svm_grid_search(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore Controls, All Data, Resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with shape:  (746, 39)\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.980 (+/-0.030) for {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.825 (+/-0.064) for {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.645 (+/-0.076) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.554 (+/-0.080) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.534 (+/-0.068) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.985 (+/-0.023) for {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.905 (+/-0.057) for {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.108) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.582 (+/-0.093) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.557 (+/-0.086) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.985 (+/-0.023) for {'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.918 (+/-0.064) for {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.907 (+/-0.064) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.769 (+/-0.081) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.552 (+/-0.079) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.985 (+/-0.023) for {'C': 1000, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.918 (+/-0.064) for {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.940 (+/-0.036) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.878 (+/-0.083) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.752 (+/-0.068) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.784 (+/-0.095) for {'C': 1, 'kernel': 'linear'}\n",
      "0.836 (+/-0.074) for {'C': 10, 'kernel': 'linear'}\n",
      "0.872 (+/-0.078) for {'C': 100, 'kernel': 'linear'}\n",
      "0.809 (+/-0.070) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.95      0.98        65\n",
      "          2       0.98      1.00      0.99        83\n",
      "          3       0.99      1.00      0.99        92\n",
      "\n",
      "avg / total       0.99      0.99      0.99       240\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the excel file\n",
    "data = load_data(\"real_data2.xlsx\")\n",
    "\n",
    "# Ignore the Control Group\n",
    "filtered_data = filter_data(data, include_control=False)\n",
    "\n",
    "# Resample the data so that there are even numbers of each label\n",
    "resampled_data = resample_data(filtered_data)\n",
    "\n",
    "# Split predictor and response data\n",
    "X, y = split_x_y_data(resampled_data)\n",
    "\n",
    "# Shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "\n",
    "# standardize the data\n",
    "X_train_std, X_test_std = standardize_data(X_train, X_test)\n",
    "\n",
    "# Perform a grid search to find best SVC model\n",
    "svm_grid_search(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore Controls, 7 Regions and UPDRS, Resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with shape:  (746, 39)\n",
      "# Tuning hyper-parameters for f1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the excel file\n",
    "data = load_data(\"real_data2.xlsx\")\n",
    "\n",
    "# Only grab the columns of interest.  TODO: Replace with list derived from feature selection\n",
    "columns_of_interest = [\"GroupID\",\"SCP_FW\",\"MCP_FW\",\"Putamen_FA\",\"Caudate_FA\",\"STN_FW\", \"RN_FW\", \"Thalamus_FA\", \"UPDRS\"]\n",
    "filtered_data = filter_data(data, columns=columns_of_interest, include_control=False)\n",
    "\n",
    "# Resample the data so that there are even numbers of each label\n",
    "resampled_data = resample_data(filtered_data)\n",
    "\n",
    "# Split predictor and response data\n",
    "X, y = split_x_y_data(resampled_data)\n",
    "\n",
    "# Shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "\n",
    "# standardize the data\n",
    "X_train_std, X_test_std = standardize_data(X_train, X_test)\n",
    "\n",
    "# Perform a grid search to find best SVC model\n",
    "svm_grid_search(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
